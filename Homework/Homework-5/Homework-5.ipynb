{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4loUZVZvdkmP6EIvwnOr4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xx39xx16/KWU-AI-Programming/blob/main/Homework-5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWyIksxAVIh3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#데이터셋 읽기\n",
        "df = pd.read_csv('./drive/MyDrive/Colab Notebooks/data_2023/dataset/winequality-red.csv')\n",
        "\n",
        "print(df['quality'].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'quality' 열에 대한 원-핫 인코딩\n",
        "y = pd.get_dummies(df['quality'])\n",
        "\n",
        "# 'quality' 열을 제외한 나머지를 입력 데이터로 사용\n",
        "X = df.drop('quality', axis=1)\n",
        "\n",
        "# 데이터셋의 차원을 확인 (디버깅을 위해)\n",
        "print(X.shape, y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty0ene8QXr-E",
        "outputId": "c78d6b88-e5d2-4d4c-8782-5a71961fdbc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1599, 11) (1599, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 정규화\n",
        "# 성능 향상을 위해 정규화 부분을 추가해줌\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "GlnsUjLKZ5Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train과 test set 나누기\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "MyvoG5Pi7Rn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# k-폴드 교차 검증 설정\n",
        "k = 5\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "fold_no = 1  # fold_no 변수 초기화\n",
        "acc_per_fold = []\n",
        "\n",
        "# KFold 교차 검증 수행\n",
        "for train, val in kf.split(X_train, y_train):\n",
        "    # 훈련 데이터와 검증 데이터 분할\n",
        "    X_train_fold, X_val_fold = X_train[train], X_train[val]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train], y_train.iloc[val]\n",
        "    # 모델 구축\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_shape=(X_train_fold.shape[1],), activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(y_train_fold.shape[1], activation='softmax'))\n",
        "    model.summary()\n",
        "\n",
        "    # 모델 컴파일\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "    # 체크포인트 및 얼리 스토핑 설정\n",
        "    checkpointer = ModelCheckpoint('best_model_fold_{}.h5'.format(fold_no), save_best_only=True, monitor='val_loss', mode='min')\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "\n",
        "    # 모델 학습\n",
        "    history = model.fit(X_train_fold, y_train_fold, epochs=370, batch_size=36, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping, checkpointer], verbose=1)\n",
        "\n",
        "     # 성능 평가\n",
        "    scores = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    fold_no += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz5bPVZNatRH",
        "outputId": "5e62ecfc-c932-4dd9-a9d1-71a365b2bbb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_39 (Dense)            (None, 64)                768       \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 6)                 198       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3046 (11.90 KB)\n",
            "Trainable params: 3046 (11.90 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/370\n",
            "29/29 [==============================] - 1s 10ms/step - loss: 1.6207 - accuracy: 0.3245 - val_loss: 1.3963 - val_accuracy: 0.3594\n",
            "Epoch 2/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.3053 - accuracy: 0.4409 - val_loss: 1.1828 - val_accuracy: 0.5508\n",
            "Epoch 3/370\n",
            " 1/29 [>.............................] - ETA: 0s - loss: 1.2072 - accuracy: 0.4444"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 4ms/step - loss: 1.2060 - accuracy: 0.4858 - val_loss: 1.1326 - val_accuracy: 0.5586\n",
            "Epoch 4/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.1684 - accuracy: 0.5513 - val_loss: 1.1126 - val_accuracy: 0.6133\n",
            "Epoch 5/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.1465 - accuracy: 0.5630 - val_loss: 1.0899 - val_accuracy: 0.6055\n",
            "Epoch 6/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.1210 - accuracy: 0.5503 - val_loss: 1.0721 - val_accuracy: 0.6133\n",
            "Epoch 7/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 1.0977 - accuracy: 0.5591 - val_loss: 1.0395 - val_accuracy: 0.6016\n",
            "Epoch 8/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 1.0691 - accuracy: 0.5523 - val_loss: 1.0461 - val_accuracy: 0.5898\n",
            "Epoch 9/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 1.0511 - accuracy: 0.5699 - val_loss: 1.0104 - val_accuracy: 0.6172\n",
            "Epoch 10/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0300 - accuracy: 0.5758 - val_loss: 0.9950 - val_accuracy: 0.6250\n",
            "Epoch 11/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0176 - accuracy: 0.5738 - val_loss: 0.9837 - val_accuracy: 0.6133\n",
            "Epoch 12/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0063 - accuracy: 0.5748 - val_loss: 0.9805 - val_accuracy: 0.6250\n",
            "Epoch 13/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0001 - accuracy: 0.5846 - val_loss: 0.9758 - val_accuracy: 0.6289\n",
            "Epoch 14/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9917 - accuracy: 0.5904 - val_loss: 0.9711 - val_accuracy: 0.6289\n",
            "Epoch 15/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9832 - accuracy: 0.6041 - val_loss: 0.9675 - val_accuracy: 0.6289\n",
            "Epoch 16/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9781 - accuracy: 0.6041 - val_loss: 0.9704 - val_accuracy: 0.6562\n",
            "Epoch 17/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9760 - accuracy: 0.5904 - val_loss: 0.9615 - val_accuracy: 0.6055\n",
            "Epoch 18/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9737 - accuracy: 0.5934 - val_loss: 0.9608 - val_accuracy: 0.6562\n",
            "Epoch 19/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9692 - accuracy: 0.5963 - val_loss: 0.9562 - val_accuracy: 0.6484\n",
            "Epoch 20/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9646 - accuracy: 0.5973 - val_loss: 0.9531 - val_accuracy: 0.6367\n",
            "Epoch 21/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9612 - accuracy: 0.5992 - val_loss: 0.9528 - val_accuracy: 0.6445\n",
            "Epoch 22/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9573 - accuracy: 0.6080 - val_loss: 0.9502 - val_accuracy: 0.6641\n",
            "Epoch 23/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9513 - accuracy: 0.5953 - val_loss: 0.9742 - val_accuracy: 0.6797\n",
            "Epoch 24/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9521 - accuracy: 0.5973 - val_loss: 0.9468 - val_accuracy: 0.6484\n",
            "Epoch 25/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9525 - accuracy: 0.6109 - val_loss: 0.9497 - val_accuracy: 0.6680\n",
            "Epoch 26/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9449 - accuracy: 0.6002 - val_loss: 0.9497 - val_accuracy: 0.6797\n",
            "Epoch 27/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9417 - accuracy: 0.6090 - val_loss: 0.9542 - val_accuracy: 0.6797\n",
            "Epoch 28/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9376 - accuracy: 0.6109 - val_loss: 0.9398 - val_accuracy: 0.6523\n",
            "Epoch 29/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9376 - accuracy: 0.6100 - val_loss: 0.9453 - val_accuracy: 0.6328\n",
            "Epoch 30/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9390 - accuracy: 0.6119 - val_loss: 0.9426 - val_accuracy: 0.6797\n",
            "Epoch 31/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9309 - accuracy: 0.6109 - val_loss: 0.9443 - val_accuracy: 0.6719\n",
            "Epoch 32/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9322 - accuracy: 0.6139 - val_loss: 0.9424 - val_accuracy: 0.6758\n",
            "Epoch 33/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9330 - accuracy: 0.6100 - val_loss: 0.9347 - val_accuracy: 0.6602\n",
            "Epoch 34/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9273 - accuracy: 0.6061 - val_loss: 0.9392 - val_accuracy: 0.6680\n",
            "Epoch 35/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9245 - accuracy: 0.6129 - val_loss: 0.9362 - val_accuracy: 0.6719\n",
            "Epoch 36/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9266 - accuracy: 0.6070 - val_loss: 0.9451 - val_accuracy: 0.6680\n",
            "Epoch 37/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9209 - accuracy: 0.6090 - val_loss: 0.9675 - val_accuracy: 0.6172\n",
            "Epoch 38/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9350 - accuracy: 0.6002 - val_loss: 0.9529 - val_accuracy: 0.6680\n",
            "Epoch 39/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9190 - accuracy: 0.6139 - val_loss: 0.9365 - val_accuracy: 0.6758\n",
            "Epoch 40/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9165 - accuracy: 0.6129 - val_loss: 0.9453 - val_accuracy: 0.6602\n",
            "Epoch 41/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9149 - accuracy: 0.6119 - val_loss: 0.9297 - val_accuracy: 0.6641\n",
            "Epoch 42/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9159 - accuracy: 0.6061 - val_loss: 0.9566 - val_accuracy: 0.6367\n",
            "Epoch 43/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9161 - accuracy: 0.6119 - val_loss: 0.9440 - val_accuracy: 0.6719\n",
            "Epoch 44/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9127 - accuracy: 0.6158 - val_loss: 0.9344 - val_accuracy: 0.6641\n",
            "Epoch 45/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9115 - accuracy: 0.6197 - val_loss: 0.9330 - val_accuracy: 0.6719\n",
            "Epoch 46/370\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.9128 - accuracy: 0.6325 - val_loss: 0.9300 - val_accuracy: 0.6406\n",
            "Epoch 47/370\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 0.9148 - accuracy: 0.6246 - val_loss: 0.9283 - val_accuracy: 0.6719\n",
            "Epoch 48/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9064 - accuracy: 0.6188 - val_loss: 0.9293 - val_accuracy: 0.6602\n",
            "Epoch 49/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9015 - accuracy: 0.6217 - val_loss: 0.9400 - val_accuracy: 0.6680\n",
            "Epoch 50/370\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.9012 - accuracy: 0.6158 - val_loss: 0.9346 - val_accuracy: 0.6328\n",
            "Epoch 51/370\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.9075 - accuracy: 0.6178 - val_loss: 0.9270 - val_accuracy: 0.6719\n",
            "Epoch 52/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8979 - accuracy: 0.6256 - val_loss: 0.9285 - val_accuracy: 0.6758\n",
            "Epoch 53/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8981 - accuracy: 0.6237 - val_loss: 0.9296 - val_accuracy: 0.6680\n",
            "Epoch 54/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8981 - accuracy: 0.6295 - val_loss: 0.9460 - val_accuracy: 0.6602\n",
            "Epoch 55/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8996 - accuracy: 0.6168 - val_loss: 0.9426 - val_accuracy: 0.6562\n",
            "Epoch 56/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8946 - accuracy: 0.6276 - val_loss: 0.9322 - val_accuracy: 0.6602\n",
            "Epoch 57/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8931 - accuracy: 0.6266 - val_loss: 0.9284 - val_accuracy: 0.6641\n",
            "Epoch 58/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8913 - accuracy: 0.6334 - val_loss: 0.9291 - val_accuracy: 0.6602\n",
            "Epoch 59/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8899 - accuracy: 0.6334 - val_loss: 0.9510 - val_accuracy: 0.6484\n",
            "Epoch 60/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8916 - accuracy: 0.6334 - val_loss: 0.9400 - val_accuracy: 0.6719\n",
            "Epoch 61/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8878 - accuracy: 0.6276 - val_loss: 0.9257 - val_accuracy: 0.6758\n",
            "Epoch 62/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8892 - accuracy: 0.6315 - val_loss: 0.9341 - val_accuracy: 0.6602\n",
            "Epoch 63/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8855 - accuracy: 0.6315 - val_loss: 0.9264 - val_accuracy: 0.6719\n",
            "Epoch 64/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8853 - accuracy: 0.6295 - val_loss: 0.9310 - val_accuracy: 0.6758\n",
            "Epoch 65/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8829 - accuracy: 0.6364 - val_loss: 0.9285 - val_accuracy: 0.6641\n",
            "Epoch 66/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8808 - accuracy: 0.6344 - val_loss: 0.9293 - val_accuracy: 0.6680\n",
            "Epoch 67/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8859 - accuracy: 0.6256 - val_loss: 0.9301 - val_accuracy: 0.6719\n",
            "Epoch 68/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8805 - accuracy: 0.6354 - val_loss: 0.9315 - val_accuracy: 0.6680\n",
            "Epoch 69/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8795 - accuracy: 0.6344 - val_loss: 0.9341 - val_accuracy: 0.6719\n",
            "Epoch 70/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8801 - accuracy: 0.6354 - val_loss: 0.9332 - val_accuracy: 0.6641\n",
            "Epoch 71/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8775 - accuracy: 0.6334 - val_loss: 0.9416 - val_accuracy: 0.6445\n",
            "Epoch 71: early stopping\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_42 (Dense)            (None, 64)                768       \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 6)                 198       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3046 (11.90 KB)\n",
            "Trainable params: 3046 (11.90 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/370\n",
            "29/29 [==============================] - 1s 10ms/step - loss: 1.5562 - accuracy: 0.4399 - val_loss: 1.3637 - val_accuracy: 0.4570\n",
            "Epoch 2/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.2448 - accuracy: 0.4907 - val_loss: 1.1608 - val_accuracy: 0.5703\n",
            "Epoch 3/370\n",
            " 1/29 [>.............................] - ETA: 0s - loss: 1.1711 - accuracy: 0.5000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 5ms/step - loss: 1.1394 - accuracy: 0.5601 - val_loss: 1.1100 - val_accuracy: 0.5391\n",
            "Epoch 4/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0975 - accuracy: 0.5689 - val_loss: 1.0718 - val_accuracy: 0.5469\n",
            "Epoch 5/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0669 - accuracy: 0.5709 - val_loss: 1.0381 - val_accuracy: 0.5703\n",
            "Epoch 6/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0370 - accuracy: 0.5777 - val_loss: 1.0154 - val_accuracy: 0.5625\n",
            "Epoch 7/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0169 - accuracy: 0.5865 - val_loss: 0.9896 - val_accuracy: 0.5898\n",
            "Epoch 8/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0084 - accuracy: 0.5758 - val_loss: 0.9728 - val_accuracy: 0.6016\n",
            "Epoch 9/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9958 - accuracy: 0.5943 - val_loss: 0.9722 - val_accuracy: 0.5820\n",
            "Epoch 10/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9861 - accuracy: 0.5904 - val_loss: 0.9585 - val_accuracy: 0.5977\n",
            "Epoch 11/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9799 - accuracy: 0.5865 - val_loss: 0.9505 - val_accuracy: 0.6172\n",
            "Epoch 12/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9748 - accuracy: 0.5934 - val_loss: 0.9478 - val_accuracy: 0.6094\n",
            "Epoch 13/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9731 - accuracy: 0.5943 - val_loss: 0.9470 - val_accuracy: 0.6055\n",
            "Epoch 14/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9682 - accuracy: 0.5914 - val_loss: 0.9422 - val_accuracy: 0.6133\n",
            "Epoch 15/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9625 - accuracy: 0.6031 - val_loss: 0.9384 - val_accuracy: 0.6367\n",
            "Epoch 16/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9631 - accuracy: 0.6109 - val_loss: 0.9355 - val_accuracy: 0.6289\n",
            "Epoch 17/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9541 - accuracy: 0.6051 - val_loss: 0.9353 - val_accuracy: 0.6094\n",
            "Epoch 18/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9532 - accuracy: 0.6051 - val_loss: 0.9341 - val_accuracy: 0.6172\n",
            "Epoch 19/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9527 - accuracy: 0.6051 - val_loss: 0.9344 - val_accuracy: 0.6289\n",
            "Epoch 20/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9502 - accuracy: 0.6061 - val_loss: 0.9347 - val_accuracy: 0.6172\n",
            "Epoch 21/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9434 - accuracy: 0.6158 - val_loss: 0.9327 - val_accuracy: 0.6289\n",
            "Epoch 22/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9399 - accuracy: 0.6090 - val_loss: 0.9305 - val_accuracy: 0.6445\n",
            "Epoch 23/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9429 - accuracy: 0.6168 - val_loss: 0.9287 - val_accuracy: 0.6328\n",
            "Epoch 24/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9388 - accuracy: 0.6129 - val_loss: 0.9278 - val_accuracy: 0.6367\n",
            "Epoch 25/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9356 - accuracy: 0.6100 - val_loss: 0.9295 - val_accuracy: 0.6094\n",
            "Epoch 26/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9350 - accuracy: 0.6041 - val_loss: 0.9299 - val_accuracy: 0.6406\n",
            "Epoch 27/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9306 - accuracy: 0.6139 - val_loss: 0.9268 - val_accuracy: 0.6406\n",
            "Epoch 28/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9265 - accuracy: 0.6158 - val_loss: 0.9414 - val_accuracy: 0.6055\n",
            "Epoch 29/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9318 - accuracy: 0.6149 - val_loss: 0.9375 - val_accuracy: 0.6211\n",
            "Epoch 30/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9288 - accuracy: 0.6041 - val_loss: 0.9322 - val_accuracy: 0.6367\n",
            "Epoch 31/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9290 - accuracy: 0.6207 - val_loss: 0.9310 - val_accuracy: 0.6328\n",
            "Epoch 32/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9231 - accuracy: 0.6070 - val_loss: 0.9303 - val_accuracy: 0.6211\n",
            "Epoch 33/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9187 - accuracy: 0.6246 - val_loss: 0.9321 - val_accuracy: 0.6250\n",
            "Epoch 34/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9137 - accuracy: 0.6237 - val_loss: 0.9272 - val_accuracy: 0.6289\n",
            "Epoch 35/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9193 - accuracy: 0.6227 - val_loss: 0.9281 - val_accuracy: 0.6484\n",
            "Epoch 36/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9157 - accuracy: 0.6217 - val_loss: 0.9274 - val_accuracy: 0.6250\n",
            "Epoch 37/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9146 - accuracy: 0.6276 - val_loss: 0.9314 - val_accuracy: 0.6250\n",
            "Epoch 37: early stopping\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_45 (Dense)            (None, 64)                768       \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 6)                 198       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3046 (11.90 KB)\n",
            "Trainable params: 3046 (11.90 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/370\n",
            "29/29 [==============================] - 1s 10ms/step - loss: 1.5332 - accuracy: 0.3959 - val_loss: 1.3461 - val_accuracy: 0.3945\n",
            "Epoch 2/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.2655 - accuracy: 0.4682 - val_loss: 1.1818 - val_accuracy: 0.5352\n",
            "Epoch 3/370\n",
            " 1/29 [>.............................] - ETA: 0s - loss: 1.1246 - accuracy: 0.6667"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 4ms/step - loss: 1.1657 - accuracy: 0.5347 - val_loss: 1.1314 - val_accuracy: 0.5234\n",
            "Epoch 4/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.1163 - accuracy: 0.5474 - val_loss: 1.0947 - val_accuracy: 0.5391\n",
            "Epoch 5/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0767 - accuracy: 0.5572 - val_loss: 1.0653 - val_accuracy: 0.5625\n",
            "Epoch 6/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0397 - accuracy: 0.5738 - val_loss: 1.0476 - val_accuracy: 0.5469\n",
            "Epoch 7/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0168 - accuracy: 0.5797 - val_loss: 1.0346 - val_accuracy: 0.5469\n",
            "Epoch 8/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9979 - accuracy: 0.5611 - val_loss: 1.0232 - val_accuracy: 0.5820\n",
            "Epoch 9/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9844 - accuracy: 0.5904 - val_loss: 1.0320 - val_accuracy: 0.5898\n",
            "Epoch 10/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9812 - accuracy: 0.5894 - val_loss: 1.0145 - val_accuracy: 0.5898\n",
            "Epoch 11/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9730 - accuracy: 0.5973 - val_loss: 1.0116 - val_accuracy: 0.5703\n",
            "Epoch 12/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9624 - accuracy: 0.5982 - val_loss: 1.0104 - val_accuracy: 0.5586\n",
            "Epoch 13/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9561 - accuracy: 0.6080 - val_loss: 1.0084 - val_accuracy: 0.5938\n",
            "Epoch 14/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9536 - accuracy: 0.6158 - val_loss: 1.0062 - val_accuracy: 0.5898\n",
            "Epoch 15/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9530 - accuracy: 0.6109 - val_loss: 1.0075 - val_accuracy: 0.6016\n",
            "Epoch 16/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9517 - accuracy: 0.6168 - val_loss: 1.0003 - val_accuracy: 0.5859\n",
            "Epoch 17/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9450 - accuracy: 0.6197 - val_loss: 1.0055 - val_accuracy: 0.5898\n",
            "Epoch 18/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9468 - accuracy: 0.6188 - val_loss: 1.0046 - val_accuracy: 0.5820\n",
            "Epoch 19/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9398 - accuracy: 0.6070 - val_loss: 1.0100 - val_accuracy: 0.5938\n",
            "Epoch 20/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9337 - accuracy: 0.6217 - val_loss: 1.0138 - val_accuracy: 0.5898\n",
            "Epoch 21/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9387 - accuracy: 0.6149 - val_loss: 0.9979 - val_accuracy: 0.5820\n",
            "Epoch 22/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9387 - accuracy: 0.6237 - val_loss: 1.0021 - val_accuracy: 0.6055\n",
            "Epoch 23/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9279 - accuracy: 0.6217 - val_loss: 0.9940 - val_accuracy: 0.5938\n",
            "Epoch 24/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9313 - accuracy: 0.6217 - val_loss: 0.9903 - val_accuracy: 0.5898\n",
            "Epoch 25/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9274 - accuracy: 0.6168 - val_loss: 0.9919 - val_accuracy: 0.5977\n",
            "Epoch 26/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9242 - accuracy: 0.6256 - val_loss: 0.9909 - val_accuracy: 0.6094\n",
            "Epoch 27/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9237 - accuracy: 0.6246 - val_loss: 0.9852 - val_accuracy: 0.6016\n",
            "Epoch 28/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9242 - accuracy: 0.6217 - val_loss: 0.9838 - val_accuracy: 0.6016\n",
            "Epoch 29/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9217 - accuracy: 0.6207 - val_loss: 0.9887 - val_accuracy: 0.5938\n",
            "Epoch 30/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9171 - accuracy: 0.6207 - val_loss: 0.9890 - val_accuracy: 0.6016\n",
            "Epoch 31/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9210 - accuracy: 0.6344 - val_loss: 0.9824 - val_accuracy: 0.6016\n",
            "Epoch 32/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9149 - accuracy: 0.6285 - val_loss: 0.9804 - val_accuracy: 0.6055\n",
            "Epoch 33/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9126 - accuracy: 0.6315 - val_loss: 0.9781 - val_accuracy: 0.6133\n",
            "Epoch 34/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9106 - accuracy: 0.6305 - val_loss: 0.9855 - val_accuracy: 0.5977\n",
            "Epoch 35/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9108 - accuracy: 0.6354 - val_loss: 0.9808 - val_accuracy: 0.5938\n",
            "Epoch 36/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9141 - accuracy: 0.6246 - val_loss: 0.9746 - val_accuracy: 0.6016\n",
            "Epoch 37/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9097 - accuracy: 0.6344 - val_loss: 0.9786 - val_accuracy: 0.5938\n",
            "Epoch 38/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9077 - accuracy: 0.6285 - val_loss: 0.9820 - val_accuracy: 0.5938\n",
            "Epoch 39/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9061 - accuracy: 0.6413 - val_loss: 0.9746 - val_accuracy: 0.6055\n",
            "Epoch 40/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9064 - accuracy: 0.6393 - val_loss: 0.9797 - val_accuracy: 0.5977\n",
            "Epoch 41/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9006 - accuracy: 0.6334 - val_loss: 0.9738 - val_accuracy: 0.6016\n",
            "Epoch 42/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9024 - accuracy: 0.6305 - val_loss: 0.9725 - val_accuracy: 0.6094\n",
            "Epoch 43/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8985 - accuracy: 0.6276 - val_loss: 0.9720 - val_accuracy: 0.6133\n",
            "Epoch 44/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9010 - accuracy: 0.6325 - val_loss: 0.9710 - val_accuracy: 0.5938\n",
            "Epoch 45/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8981 - accuracy: 0.6295 - val_loss: 0.9772 - val_accuracy: 0.5977\n",
            "Epoch 46/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8939 - accuracy: 0.6285 - val_loss: 0.9723 - val_accuracy: 0.6055\n",
            "Epoch 47/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8970 - accuracy: 0.6334 - val_loss: 0.9751 - val_accuracy: 0.6016\n",
            "Epoch 48/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8973 - accuracy: 0.6334 - val_loss: 0.9645 - val_accuracy: 0.6133\n",
            "Epoch 49/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8954 - accuracy: 0.6354 - val_loss: 0.9645 - val_accuracy: 0.6133\n",
            "Epoch 50/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8933 - accuracy: 0.6354 - val_loss: 0.9685 - val_accuracy: 0.6016\n",
            "Epoch 51/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8923 - accuracy: 0.6334 - val_loss: 0.9627 - val_accuracy: 0.6211\n",
            "Epoch 52/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8891 - accuracy: 0.6354 - val_loss: 0.9658 - val_accuracy: 0.6250\n",
            "Epoch 53/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8881 - accuracy: 0.6432 - val_loss: 0.9680 - val_accuracy: 0.6055\n",
            "Epoch 54/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8880 - accuracy: 0.6393 - val_loss: 0.9625 - val_accuracy: 0.6250\n",
            "Epoch 55/370\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.8896 - accuracy: 0.6422 - val_loss: 0.9623 - val_accuracy: 0.6055\n",
            "Epoch 56/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8887 - accuracy: 0.6413 - val_loss: 0.9604 - val_accuracy: 0.6094\n",
            "Epoch 57/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8822 - accuracy: 0.6432 - val_loss: 0.9651 - val_accuracy: 0.6016\n",
            "Epoch 58/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8828 - accuracy: 0.6413 - val_loss: 0.9613 - val_accuracy: 0.5938\n",
            "Epoch 59/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8791 - accuracy: 0.6364 - val_loss: 0.9619 - val_accuracy: 0.6055\n",
            "Epoch 60/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8829 - accuracy: 0.6325 - val_loss: 0.9595 - val_accuracy: 0.6016\n",
            "Epoch 61/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8818 - accuracy: 0.6442 - val_loss: 0.9565 - val_accuracy: 0.6016\n",
            "Epoch 62/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8784 - accuracy: 0.6403 - val_loss: 0.9600 - val_accuracy: 0.6133\n",
            "Epoch 63/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8763 - accuracy: 0.6413 - val_loss: 0.9574 - val_accuracy: 0.6133\n",
            "Epoch 64/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8760 - accuracy: 0.6520 - val_loss: 0.9580 - val_accuracy: 0.6172\n",
            "Epoch 65/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8747 - accuracy: 0.6500 - val_loss: 0.9551 - val_accuracy: 0.6172\n",
            "Epoch 66/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8766 - accuracy: 0.6403 - val_loss: 0.9586 - val_accuracy: 0.6055\n",
            "Epoch 67/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8764 - accuracy: 0.6491 - val_loss: 0.9625 - val_accuracy: 0.5938\n",
            "Epoch 68/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8763 - accuracy: 0.6393 - val_loss: 0.9624 - val_accuracy: 0.6328\n",
            "Epoch 69/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8733 - accuracy: 0.6530 - val_loss: 0.9548 - val_accuracy: 0.6172\n",
            "Epoch 70/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8772 - accuracy: 0.6403 - val_loss: 0.9554 - val_accuracy: 0.6055\n",
            "Epoch 71/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8703 - accuracy: 0.6461 - val_loss: 0.9533 - val_accuracy: 0.6094\n",
            "Epoch 72/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8683 - accuracy: 0.6540 - val_loss: 0.9555 - val_accuracy: 0.5977\n",
            "Epoch 73/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8655 - accuracy: 0.6559 - val_loss: 0.9556 - val_accuracy: 0.5977\n",
            "Epoch 74/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8671 - accuracy: 0.6393 - val_loss: 0.9518 - val_accuracy: 0.6094\n",
            "Epoch 75/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8634 - accuracy: 0.6491 - val_loss: 0.9505 - val_accuracy: 0.6172\n",
            "Epoch 76/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8625 - accuracy: 0.6559 - val_loss: 0.9522 - val_accuracy: 0.6016\n",
            "Epoch 77/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8651 - accuracy: 0.6500 - val_loss: 0.9499 - val_accuracy: 0.6094\n",
            "Epoch 78/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8634 - accuracy: 0.6481 - val_loss: 0.9623 - val_accuracy: 0.6133\n",
            "Epoch 79/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8640 - accuracy: 0.6461 - val_loss: 0.9490 - val_accuracy: 0.6211\n",
            "Epoch 80/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8707 - accuracy: 0.6422 - val_loss: 0.9492 - val_accuracy: 0.6211\n",
            "Epoch 81/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8617 - accuracy: 0.6452 - val_loss: 0.9552 - val_accuracy: 0.6016\n",
            "Epoch 82/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8640 - accuracy: 0.6422 - val_loss: 0.9515 - val_accuracy: 0.6211\n",
            "Epoch 83/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8554 - accuracy: 0.6491 - val_loss: 0.9500 - val_accuracy: 0.6055\n",
            "Epoch 84/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8574 - accuracy: 0.6588 - val_loss: 0.9481 - val_accuracy: 0.6133\n",
            "Epoch 85/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8553 - accuracy: 0.6510 - val_loss: 0.9424 - val_accuracy: 0.6211\n",
            "Epoch 86/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8530 - accuracy: 0.6520 - val_loss: 0.9460 - val_accuracy: 0.6367\n",
            "Epoch 87/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8545 - accuracy: 0.6549 - val_loss: 0.9444 - val_accuracy: 0.6250\n",
            "Epoch 88/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8549 - accuracy: 0.6461 - val_loss: 0.9586 - val_accuracy: 0.5938\n",
            "Epoch 89/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8535 - accuracy: 0.6442 - val_loss: 0.9473 - val_accuracy: 0.6133\n",
            "Epoch 90/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8526 - accuracy: 0.6540 - val_loss: 0.9459 - val_accuracy: 0.6250\n",
            "Epoch 91/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8542 - accuracy: 0.6549 - val_loss: 0.9456 - val_accuracy: 0.6172\n",
            "Epoch 92/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8532 - accuracy: 0.6618 - val_loss: 0.9459 - val_accuracy: 0.6055\n",
            "Epoch 93/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8495 - accuracy: 0.6549 - val_loss: 0.9424 - val_accuracy: 0.6250\n",
            "Epoch 94/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8549 - accuracy: 0.6520 - val_loss: 0.9453 - val_accuracy: 0.6133\n",
            "Epoch 95/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8545 - accuracy: 0.6618 - val_loss: 0.9478 - val_accuracy: 0.6055\n",
            "Epoch 96/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8584 - accuracy: 0.6334 - val_loss: 0.9344 - val_accuracy: 0.6211\n",
            "Epoch 97/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8456 - accuracy: 0.6579 - val_loss: 0.9447 - val_accuracy: 0.6211\n",
            "Epoch 98/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8490 - accuracy: 0.6598 - val_loss: 0.9409 - val_accuracy: 0.6211\n",
            "Epoch 99/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8460 - accuracy: 0.6491 - val_loss: 0.9436 - val_accuracy: 0.6211\n",
            "Epoch 100/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8430 - accuracy: 0.6676 - val_loss: 0.9445 - val_accuracy: 0.6133\n",
            "Epoch 101/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8486 - accuracy: 0.6559 - val_loss: 0.9339 - val_accuracy: 0.6094\n",
            "Epoch 102/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8444 - accuracy: 0.6676 - val_loss: 0.9395 - val_accuracy: 0.6094\n",
            "Epoch 103/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8416 - accuracy: 0.6559 - val_loss: 0.9426 - val_accuracy: 0.6211\n",
            "Epoch 104/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8402 - accuracy: 0.6598 - val_loss: 0.9399 - val_accuracy: 0.6172\n",
            "Epoch 105/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8388 - accuracy: 0.6686 - val_loss: 0.9426 - val_accuracy: 0.6094\n",
            "Epoch 106/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8420 - accuracy: 0.6598 - val_loss: 0.9378 - val_accuracy: 0.6016\n",
            "Epoch 107/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8415 - accuracy: 0.6530 - val_loss: 0.9341 - val_accuracy: 0.6094\n",
            "Epoch 108/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8369 - accuracy: 0.6706 - val_loss: 0.9389 - val_accuracy: 0.6172\n",
            "Epoch 109/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8336 - accuracy: 0.6598 - val_loss: 0.9433 - val_accuracy: 0.6250\n",
            "Epoch 110/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8397 - accuracy: 0.6618 - val_loss: 0.9369 - val_accuracy: 0.6094\n",
            "Epoch 111/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8343 - accuracy: 0.6520 - val_loss: 0.9396 - val_accuracy: 0.6250\n",
            "Epoch 111: early stopping\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_48 (Dense)            (None, 64)                768       \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 6)                 198       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3046 (11.90 KB)\n",
            "Trainable params: 3046 (11.90 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/370\n",
            "29/29 [==============================] - 1s 10ms/step - loss: 1.6822 - accuracy: 0.2845 - val_loss: 1.5585 - val_accuracy: 0.4141\n",
            "Epoch 2/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.4190 - accuracy: 0.4350 - val_loss: 1.3212 - val_accuracy: 0.4219\n",
            "Epoch 3/370\n",
            " 1/29 [>.............................] - ETA: 0s - loss: 1.3161 - accuracy: 0.4444"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 4ms/step - loss: 1.2105 - accuracy: 0.5024 - val_loss: 1.1956 - val_accuracy: 0.5547\n",
            "Epoch 4/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.1268 - accuracy: 0.5513 - val_loss: 1.1388 - val_accuracy: 0.5352\n",
            "Epoch 5/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0849 - accuracy: 0.5386 - val_loss: 1.0955 - val_accuracy: 0.5312\n",
            "Epoch 6/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0504 - accuracy: 0.5572 - val_loss: 1.0603 - val_accuracy: 0.5508\n",
            "Epoch 7/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0277 - accuracy: 0.5689 - val_loss: 1.0363 - val_accuracy: 0.5703\n",
            "Epoch 8/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.5640 - val_loss: 1.0219 - val_accuracy: 0.5781\n",
            "Epoch 9/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9993 - accuracy: 0.5806 - val_loss: 1.0151 - val_accuracy: 0.5742\n",
            "Epoch 10/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9897 - accuracy: 0.5963 - val_loss: 0.9993 - val_accuracy: 0.5664\n",
            "Epoch 11/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9850 - accuracy: 0.5894 - val_loss: 0.9988 - val_accuracy: 0.5742\n",
            "Epoch 12/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9825 - accuracy: 0.5885 - val_loss: 0.9892 - val_accuracy: 0.5781\n",
            "Epoch 13/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9779 - accuracy: 0.5904 - val_loss: 0.9846 - val_accuracy: 0.5977\n",
            "Epoch 14/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9719 - accuracy: 0.5875 - val_loss: 0.9931 - val_accuracy: 0.6211\n",
            "Epoch 15/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9683 - accuracy: 0.6002 - val_loss: 1.0000 - val_accuracy: 0.6328\n",
            "Epoch 16/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9639 - accuracy: 0.6061 - val_loss: 0.9790 - val_accuracy: 0.6094\n",
            "Epoch 17/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9625 - accuracy: 0.6139 - val_loss: 0.9839 - val_accuracy: 0.5938\n",
            "Epoch 18/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9551 - accuracy: 0.6168 - val_loss: 0.9747 - val_accuracy: 0.6094\n",
            "Epoch 19/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9525 - accuracy: 0.6119 - val_loss: 0.9741 - val_accuracy: 0.6133\n",
            "Epoch 20/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9536 - accuracy: 0.6109 - val_loss: 0.9786 - val_accuracy: 0.6406\n",
            "Epoch 21/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9473 - accuracy: 0.6139 - val_loss: 0.9740 - val_accuracy: 0.6172\n",
            "Epoch 22/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9432 - accuracy: 0.6129 - val_loss: 0.9694 - val_accuracy: 0.6133\n",
            "Epoch 23/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9460 - accuracy: 0.6070 - val_loss: 0.9680 - val_accuracy: 0.6211\n",
            "Epoch 24/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9450 - accuracy: 0.6090 - val_loss: 0.9765 - val_accuracy: 0.6172\n",
            "Epoch 25/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9404 - accuracy: 0.6129 - val_loss: 0.9664 - val_accuracy: 0.6016\n",
            "Epoch 26/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9371 - accuracy: 0.6139 - val_loss: 0.9667 - val_accuracy: 0.6211\n",
            "Epoch 27/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9325 - accuracy: 0.6207 - val_loss: 0.9638 - val_accuracy: 0.6094\n",
            "Epoch 28/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9330 - accuracy: 0.6266 - val_loss: 0.9621 - val_accuracy: 0.6172\n",
            "Epoch 29/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9311 - accuracy: 0.6178 - val_loss: 0.9656 - val_accuracy: 0.6211\n",
            "Epoch 30/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9270 - accuracy: 0.6217 - val_loss: 0.9804 - val_accuracy: 0.6172\n",
            "Epoch 31/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9272 - accuracy: 0.6237 - val_loss: 0.9719 - val_accuracy: 0.6250\n",
            "Epoch 32/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9235 - accuracy: 0.6266 - val_loss: 0.9749 - val_accuracy: 0.6133\n",
            "Epoch 33/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9217 - accuracy: 0.6227 - val_loss: 0.9626 - val_accuracy: 0.6211\n",
            "Epoch 34/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9206 - accuracy: 0.6158 - val_loss: 0.9763 - val_accuracy: 0.6133\n",
            "Epoch 35/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9226 - accuracy: 0.6129 - val_loss: 0.9728 - val_accuracy: 0.6133\n",
            "Epoch 36/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9206 - accuracy: 0.6266 - val_loss: 0.9667 - val_accuracy: 0.6250\n",
            "Epoch 37/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9156 - accuracy: 0.6237 - val_loss: 0.9648 - val_accuracy: 0.6250\n",
            "Epoch 38/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9132 - accuracy: 0.6227 - val_loss: 0.9675 - val_accuracy: 0.6211\n",
            "Epoch 38: early stopping\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_51 (Dense)            (None, 64)                768       \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 6)                 198       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3046 (11.90 KB)\n",
            "Trainable params: 3046 (11.90 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/370\n",
            "29/29 [==============================] - 1s 15ms/step - loss: 1.7158 - accuracy: 0.3945 - val_loss: 1.6107 - val_accuracy: 0.3882\n",
            "Epoch 2/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 1.4557 - accuracy: 0.4414 - val_loss: 1.3472 - val_accuracy: 0.3882\n",
            "Epoch 3/370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 6ms/step - loss: 1.2300 - accuracy: 0.4590 - val_loss: 1.2089 - val_accuracy: 0.4471\n",
            "Epoch 4/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 1.1516 - accuracy: 0.5332 - val_loss: 1.1610 - val_accuracy: 0.5412\n",
            "Epoch 5/370\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 1.1172 - accuracy: 0.5459 - val_loss: 1.1300 - val_accuracy: 0.5373\n",
            "Epoch 6/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 1.0859 - accuracy: 0.5781 - val_loss: 1.1242 - val_accuracy: 0.4706\n",
            "Epoch 7/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 1.0637 - accuracy: 0.5586 - val_loss: 1.0846 - val_accuracy: 0.5216\n",
            "Epoch 8/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 1.0350 - accuracy: 0.5762 - val_loss: 1.0667 - val_accuracy: 0.5255\n",
            "Epoch 9/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 1.0153 - accuracy: 0.5811 - val_loss: 1.0486 - val_accuracy: 0.5412\n",
            "Epoch 10/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 1.0010 - accuracy: 0.5850 - val_loss: 1.0390 - val_accuracy: 0.5255\n",
            "Epoch 11/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9895 - accuracy: 0.5947 - val_loss: 1.0306 - val_accuracy: 0.5294\n",
            "Epoch 12/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9808 - accuracy: 0.5938 - val_loss: 1.0278 - val_accuracy: 0.5529\n",
            "Epoch 13/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9758 - accuracy: 0.5967 - val_loss: 1.0233 - val_accuracy: 0.5373\n",
            "Epoch 14/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9697 - accuracy: 0.6055 - val_loss: 1.0180 - val_accuracy: 0.5490\n",
            "Epoch 15/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9663 - accuracy: 0.6074 - val_loss: 1.0163 - val_accuracy: 0.5490\n",
            "Epoch 16/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9654 - accuracy: 0.6055 - val_loss: 1.0238 - val_accuracy: 0.5333\n",
            "Epoch 17/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9609 - accuracy: 0.6182 - val_loss: 1.0380 - val_accuracy: 0.5255\n",
            "Epoch 18/370\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.9570 - accuracy: 0.6191 - val_loss: 1.0161 - val_accuracy: 0.5412\n",
            "Epoch 19/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9523 - accuracy: 0.6152 - val_loss: 1.0101 - val_accuracy: 0.5490\n",
            "Epoch 20/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9481 - accuracy: 0.6230 - val_loss: 1.0159 - val_accuracy: 0.5451\n",
            "Epoch 21/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9461 - accuracy: 0.6289 - val_loss: 1.0097 - val_accuracy: 0.5490\n",
            "Epoch 22/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9427 - accuracy: 0.6230 - val_loss: 1.0070 - val_accuracy: 0.5490\n",
            "Epoch 23/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9410 - accuracy: 0.6270 - val_loss: 1.0053 - val_accuracy: 0.5333\n",
            "Epoch 24/370\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.9409 - accuracy: 0.6318 - val_loss: 1.0042 - val_accuracy: 0.5529\n",
            "Epoch 25/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9388 - accuracy: 0.6357 - val_loss: 1.0201 - val_accuracy: 0.5373\n",
            "Epoch 26/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9385 - accuracy: 0.6318 - val_loss: 1.0109 - val_accuracy: 0.5451\n",
            "Epoch 27/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9355 - accuracy: 0.6289 - val_loss: 1.0085 - val_accuracy: 0.5490\n",
            "Epoch 28/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9328 - accuracy: 0.6318 - val_loss: 1.0067 - val_accuracy: 0.5412\n",
            "Epoch 29/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9287 - accuracy: 0.6260 - val_loss: 1.0009 - val_accuracy: 0.5412\n",
            "Epoch 30/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9265 - accuracy: 0.6348 - val_loss: 0.9981 - val_accuracy: 0.5529\n",
            "Epoch 31/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9275 - accuracy: 0.6367 - val_loss: 1.0039 - val_accuracy: 0.5490\n",
            "Epoch 32/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9244 - accuracy: 0.6318 - val_loss: 1.0056 - val_accuracy: 0.5373\n",
            "Epoch 33/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9224 - accuracy: 0.6387 - val_loss: 1.0031 - val_accuracy: 0.5490\n",
            "Epoch 34/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9238 - accuracy: 0.6387 - val_loss: 0.9980 - val_accuracy: 0.5451\n",
            "Epoch 35/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9225 - accuracy: 0.6436 - val_loss: 1.0048 - val_accuracy: 0.5373\n",
            "Epoch 36/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9191 - accuracy: 0.6357 - val_loss: 0.9987 - val_accuracy: 0.5412\n",
            "Epoch 37/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9169 - accuracy: 0.6475 - val_loss: 1.0096 - val_accuracy: 0.5451\n",
            "Epoch 38/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9133 - accuracy: 0.6445 - val_loss: 0.9991 - val_accuracy: 0.5451\n",
            "Epoch 39/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9151 - accuracy: 0.6318 - val_loss: 0.9965 - val_accuracy: 0.5373\n",
            "Epoch 40/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9184 - accuracy: 0.6377 - val_loss: 0.9946 - val_accuracy: 0.5451\n",
            "Epoch 41/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9148 - accuracy: 0.6367 - val_loss: 0.9925 - val_accuracy: 0.5529\n",
            "Epoch 42/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9131 - accuracy: 0.6367 - val_loss: 0.9922 - val_accuracy: 0.5490\n",
            "Epoch 43/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9086 - accuracy: 0.6367 - val_loss: 0.9992 - val_accuracy: 0.5451\n",
            "Epoch 44/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9072 - accuracy: 0.6465 - val_loss: 0.9980 - val_accuracy: 0.5529\n",
            "Epoch 45/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9075 - accuracy: 0.6387 - val_loss: 0.9912 - val_accuracy: 0.5529\n",
            "Epoch 46/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9104 - accuracy: 0.6475 - val_loss: 0.9919 - val_accuracy: 0.5529\n",
            "Epoch 47/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9027 - accuracy: 0.6436 - val_loss: 1.0028 - val_accuracy: 0.5412\n",
            "Epoch 48/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9032 - accuracy: 0.6455 - val_loss: 0.9917 - val_accuracy: 0.5490\n",
            "Epoch 49/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9007 - accuracy: 0.6455 - val_loss: 0.9896 - val_accuracy: 0.5569\n",
            "Epoch 50/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9026 - accuracy: 0.6494 - val_loss: 0.9948 - val_accuracy: 0.5412\n",
            "Epoch 51/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9003 - accuracy: 0.6475 - val_loss: 1.0009 - val_accuracy: 0.5412\n",
            "Epoch 52/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8984 - accuracy: 0.6543 - val_loss: 0.9973 - val_accuracy: 0.5412\n",
            "Epoch 53/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9025 - accuracy: 0.6484 - val_loss: 0.9959 - val_accuracy: 0.5373\n",
            "Epoch 54/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8976 - accuracy: 0.6543 - val_loss: 0.9894 - val_accuracy: 0.5529\n",
            "Epoch 55/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8983 - accuracy: 0.6533 - val_loss: 0.9895 - val_accuracy: 0.5451\n",
            "Epoch 56/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8982 - accuracy: 0.6445 - val_loss: 0.9900 - val_accuracy: 0.5608\n",
            "Epoch 57/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8967 - accuracy: 0.6592 - val_loss: 0.9900 - val_accuracy: 0.5412\n",
            "Epoch 58/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8979 - accuracy: 0.6514 - val_loss: 0.9903 - val_accuracy: 0.5490\n",
            "Epoch 59/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8953 - accuracy: 0.6445 - val_loss: 0.9929 - val_accuracy: 0.5569\n",
            "Epoch 60/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8905 - accuracy: 0.6514 - val_loss: 0.9930 - val_accuracy: 0.5451\n",
            "Epoch 61/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8915 - accuracy: 0.6543 - val_loss: 0.9886 - val_accuracy: 0.5529\n",
            "Epoch 62/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8863 - accuracy: 0.6494 - val_loss: 0.9889 - val_accuracy: 0.5490\n",
            "Epoch 63/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8857 - accuracy: 0.6592 - val_loss: 1.0015 - val_accuracy: 0.5490\n",
            "Epoch 64/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8895 - accuracy: 0.6523 - val_loss: 0.9907 - val_accuracy: 0.5608\n",
            "Epoch 65/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8851 - accuracy: 0.6543 - val_loss: 0.9891 - val_accuracy: 0.5412\n",
            "Epoch 66/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8847 - accuracy: 0.6553 - val_loss: 1.0010 - val_accuracy: 0.5412\n",
            "Epoch 67/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8865 - accuracy: 0.6523 - val_loss: 0.9942 - val_accuracy: 0.5529\n",
            "Epoch 68/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8827 - accuracy: 0.6572 - val_loss: 0.9892 - val_accuracy: 0.5608\n",
            "Epoch 69/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8826 - accuracy: 0.6572 - val_loss: 0.9901 - val_accuracy: 0.5569\n",
            "Epoch 70/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8820 - accuracy: 0.6514 - val_loss: 0.9911 - val_accuracy: 0.5608\n",
            "Epoch 71/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8822 - accuracy: 0.6680 - val_loss: 1.0019 - val_accuracy: 0.5373\n",
            "Epoch 71: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 교차 검증 결과 분석\n",
        "average_accuracy = np.mean(acc_per_fold)\n",
        "print(f'Average accuracy across all folds: {average_accuracy:.2f}%')\n",
        "\n",
        "# 정확도 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, k+1), acc_per_fold, marker='o', linestyle='-', color='b')\n",
        "plt.title('Accuracy per Fold')\n",
        "plt.xlabel('Fold Number')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.xticks(range(1, k+1))\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "HVN_e-cZKvEm",
        "outputId": "50895c47-3e8f-482b-c0cc-0300f7c5087c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy across all folds: 61.06%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 데이터셋에 대한 모델 성능 평가\n",
        "# 전체 데이터셋에 대해 동일한 모델 아키텍처를 사용하여 학습 및 평가를 수행합\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_shape=(X_scaled.shape[1],), activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model.fit(X_scaled, y, epochs=100, batch_size=32, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKCwQ4mqK2Ud",
        "outputId": "62d14edc-e469-4bbf-efef-3dc569f8bdc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 1s 2ms/step - loss: 1.4741 - accuracy: 0.4403\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 1.1669 - accuracy: 0.5210\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 1.0936 - accuracy: 0.5416\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 1.0486 - accuracy: 0.5616\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 1.0177 - accuracy: 0.5641\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9950 - accuracy: 0.5922\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9849 - accuracy: 0.5922\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9771 - accuracy: 0.5979\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9716 - accuracy: 0.5985\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9655 - accuracy: 0.5972\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9611 - accuracy: 0.6010\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9570 - accuracy: 0.5954\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9533 - accuracy: 0.5991\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9480 - accuracy: 0.6060\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9455 - accuracy: 0.6066\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9391 - accuracy: 0.6198\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9402 - accuracy: 0.6048\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9332 - accuracy: 0.6066\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9333 - accuracy: 0.6116\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9315 - accuracy: 0.6123\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9256 - accuracy: 0.6135\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9253 - accuracy: 0.6060\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9192 - accuracy: 0.6123\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9217 - accuracy: 0.6141\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9142 - accuracy: 0.6154\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9150 - accuracy: 0.6110\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9176 - accuracy: 0.6166\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.6191\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.6148\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9050 - accuracy: 0.6204\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9034 - accuracy: 0.6273\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9025 - accuracy: 0.6273\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9021 - accuracy: 0.6223\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9047 - accuracy: 0.6273\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8981 - accuracy: 0.6229\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8973 - accuracy: 0.6229\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9011 - accuracy: 0.6116\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8968 - accuracy: 0.6235\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8923 - accuracy: 0.6185\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8923 - accuracy: 0.6248\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8893 - accuracy: 0.6266\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8875 - accuracy: 0.6279\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8895 - accuracy: 0.6298\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8891 - accuracy: 0.6291\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8840 - accuracy: 0.6285\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8868 - accuracy: 0.6241\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8874 - accuracy: 0.6148\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8818 - accuracy: 0.6379\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8809 - accuracy: 0.6291\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8779 - accuracy: 0.6310\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8776 - accuracy: 0.6298\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8767 - accuracy: 0.6341\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8786 - accuracy: 0.6241\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8729 - accuracy: 0.6385\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8774 - accuracy: 0.6273\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8755 - accuracy: 0.6329\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8699 - accuracy: 0.6348\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8758 - accuracy: 0.6291\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8701 - accuracy: 0.6385\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8700 - accuracy: 0.6391\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8725 - accuracy: 0.6391\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8687 - accuracy: 0.6316\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8701 - accuracy: 0.6291\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8678 - accuracy: 0.6323\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8660 - accuracy: 0.6417\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8659 - accuracy: 0.6391\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8654 - accuracy: 0.6248\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8621 - accuracy: 0.6366\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8661 - accuracy: 0.6398\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8610 - accuracy: 0.6385\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8632 - accuracy: 0.6310\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8654 - accuracy: 0.6279\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8609 - accuracy: 0.6442\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8591 - accuracy: 0.6404\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8603 - accuracy: 0.6329\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8570 - accuracy: 0.6373\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8601 - accuracy: 0.6341\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8534 - accuracy: 0.6398\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8572 - accuracy: 0.6335\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8569 - accuracy: 0.6354\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8544 - accuracy: 0.6329\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8515 - accuracy: 0.6391\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8546 - accuracy: 0.6354\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8505 - accuracy: 0.6404\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8505 - accuracy: 0.6435\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8493 - accuracy: 0.6460\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8494 - accuracy: 0.6429\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8487 - accuracy: 0.6304\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8486 - accuracy: 0.6479\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8465 - accuracy: 0.6454\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8502 - accuracy: 0.6467\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8447 - accuracy: 0.6435\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8458 - accuracy: 0.6373\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8499 - accuracy: 0.6360\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8410 - accuracy: 0.6423\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8407 - accuracy: 0.6448\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8424 - accuracy: 0.6404\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8444 - accuracy: 0.6373\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8435 - accuracy: 0.6448\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8405 - accuracy: 0.6423\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d780d8c1e70>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 테스트 세트에서 성능 평가\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test Set Accuracy: {test_accuracy*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OmhpV6HLCSt",
        "outputId": "e37600ab-e40b-40ed-8202-f8a599751a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Accuracy: 61.87%\n"
          ]
        }
      ]
    }
  ]
}
