{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPY2vl8vvwROD6mhp1TlR+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xx39xx16/KWU-AI-Programming/blob/main/%08Homework/Homework-5/Homework-5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWyIksxAVIh3",
        "outputId": "ff384829-0ce9-413d-c98e-6fe24527d880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[5 6 7 4 8 3]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#데이터셋 읽기\n",
        "df = pd.read_csv('./drive/MyDrive/Colab Notebooks/data_2023/dataset/winequality-red.csv')\n",
        "\n",
        "print(df['quality'].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'quality' 열에 대한 원-핫 인코딩\n",
        "y = pd.get_dummies(df['quality'])\n",
        "\n",
        "# 'quality' 열을 제외한 나머지를 입력 데이터로 사용\n",
        "X = df.drop('quality', axis=1)\n",
        "\n",
        "# 데이터셋의 차원을 확인 (디버깅을 위해)\n",
        "print(X.shape, y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty0ene8QXr-E",
        "outputId": "17141a0e-9afa-4af0-82b3-97734d0c0863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1599, 11) (1599, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 정규화\n",
        "# 성능 향상을 위해 정규화 부분을 추가해줌\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "GlnsUjLKZ5Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test set과 validation set 나누기\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "MyvoG5Pi7Rn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# k-폴드 교차 검증 설정\n",
        "k = 5\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "fold_no = 1  # fold_no 변수 초기화\n",
        "acc_per_fold = []\n",
        "\n",
        "# KFold 교차 검증 수행\n",
        "for train, val in kf.split(X_train, y_train):\n",
        "    # 훈련 데이터와 검증 데이터 분할\n",
        "    X_train_fold, X_val_fold = X_train[train], X_train[val]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train], y_train.iloc[val]\n",
        "\n",
        "    # 모델 구축\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_shape=(X_train_fold.shape[1],), activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(y_train_fold.shape[1], activation='softmax'))\n",
        "\n",
        "    # 모델 컴파일\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "    # 체크포인트 및 얼리 스토핑 설정\n",
        "    checkpointer = ModelCheckpoint('best_model_fold_{}.h5'.format(fold_no), save_best_only=True, monitor='val_loss', mode='min')\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "\n",
        "    # 모델 학습\n",
        "    history = model.fit(X_train_fold, y_train_fold, epochs=370, batch_size=36, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping, checkpointer], verbose=1)\n",
        "\n",
        "     # 성능 평가\n",
        "    scores = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "\n",
        "    fold_no += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz5bPVZNatRH",
        "outputId": "e4781943-5830-4f22-ae16-ae7bb65c6f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/370\n",
            "29/29 [==============================] - 2s 18ms/step - loss: 1.5570 - accuracy: 0.4712 - val_loss: 1.3186 - val_accuracy: 0.4961\n",
            "Epoch 2/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 1.2351 - accuracy: 0.4966 - val_loss: 1.1232 - val_accuracy: 0.5234\n",
            "Epoch 3/370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 6ms/step - loss: 1.1458 - accuracy: 0.5337 - val_loss: 1.0854 - val_accuracy: 0.5469\n",
            "Epoch 4/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 1.1070 - accuracy: 0.5533 - val_loss: 1.0536 - val_accuracy: 0.5586\n",
            "Epoch 5/370\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 1.0761 - accuracy: 0.5415 - val_loss: 1.0283 - val_accuracy: 0.5781\n",
            "Epoch 6/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 1.0485 - accuracy: 0.5562 - val_loss: 1.0221 - val_accuracy: 0.6133\n",
            "Epoch 7/370\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 1.0285 - accuracy: 0.5562 - val_loss: 0.9976 - val_accuracy: 0.6172\n",
            "Epoch 8/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0098 - accuracy: 0.5679 - val_loss: 0.9851 - val_accuracy: 0.6211\n",
            "Epoch 9/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9986 - accuracy: 0.5826 - val_loss: 0.9816 - val_accuracy: 0.6250\n",
            "Epoch 10/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9925 - accuracy: 0.5806 - val_loss: 0.9741 - val_accuracy: 0.6094\n",
            "Epoch 11/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9873 - accuracy: 0.5885 - val_loss: 0.9813 - val_accuracy: 0.6445\n",
            "Epoch 12/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9811 - accuracy: 0.5797 - val_loss: 0.9699 - val_accuracy: 0.6406\n",
            "Epoch 13/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9744 - accuracy: 0.5953 - val_loss: 0.9699 - val_accuracy: 0.6562\n",
            "Epoch 14/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9704 - accuracy: 0.5885 - val_loss: 0.9697 - val_accuracy: 0.6562\n",
            "Epoch 15/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9667 - accuracy: 0.5963 - val_loss: 0.9651 - val_accuracy: 0.6680\n",
            "Epoch 16/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9663 - accuracy: 0.5885 - val_loss: 0.9676 - val_accuracy: 0.6719\n",
            "Epoch 17/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9591 - accuracy: 0.5914 - val_loss: 0.9544 - val_accuracy: 0.6367\n",
            "Epoch 18/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9563 - accuracy: 0.6041 - val_loss: 0.9582 - val_accuracy: 0.6719\n",
            "Epoch 19/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9539 - accuracy: 0.6002 - val_loss: 0.9532 - val_accuracy: 0.6719\n",
            "Epoch 20/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9522 - accuracy: 0.6031 - val_loss: 0.9550 - val_accuracy: 0.6758\n",
            "Epoch 21/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9490 - accuracy: 0.5924 - val_loss: 0.9538 - val_accuracy: 0.6758\n",
            "Epoch 22/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9465 - accuracy: 0.5963 - val_loss: 0.9493 - val_accuracy: 0.6758\n",
            "Epoch 23/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9486 - accuracy: 0.5943 - val_loss: 0.9452 - val_accuracy: 0.6328\n",
            "Epoch 24/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9480 - accuracy: 0.5953 - val_loss: 0.9502 - val_accuracy: 0.6758\n",
            "Epoch 25/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9446 - accuracy: 0.6100 - val_loss: 0.9521 - val_accuracy: 0.6836\n",
            "Epoch 26/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9373 - accuracy: 0.6051 - val_loss: 0.9392 - val_accuracy: 0.6602\n",
            "Epoch 27/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9365 - accuracy: 0.6129 - val_loss: 0.9435 - val_accuracy: 0.6758\n",
            "Epoch 28/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9368 - accuracy: 0.6061 - val_loss: 0.9366 - val_accuracy: 0.6602\n",
            "Epoch 29/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9336 - accuracy: 0.6002 - val_loss: 0.9364 - val_accuracy: 0.6758\n",
            "Epoch 30/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9306 - accuracy: 0.6041 - val_loss: 0.9335 - val_accuracy: 0.6562\n",
            "Epoch 31/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9286 - accuracy: 0.6090 - val_loss: 0.9330 - val_accuracy: 0.6445\n",
            "Epoch 32/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9324 - accuracy: 0.6022 - val_loss: 0.9311 - val_accuracy: 0.6562\n",
            "Epoch 33/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9254 - accuracy: 0.6061 - val_loss: 0.9308 - val_accuracy: 0.6719\n",
            "Epoch 34/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9227 - accuracy: 0.6080 - val_loss: 0.9412 - val_accuracy: 0.6836\n",
            "Epoch 35/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9241 - accuracy: 0.6080 - val_loss: 0.9359 - val_accuracy: 0.6719\n",
            "Epoch 36/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9165 - accuracy: 0.6158 - val_loss: 0.9303 - val_accuracy: 0.6680\n",
            "Epoch 37/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9157 - accuracy: 0.6158 - val_loss: 0.9392 - val_accuracy: 0.6797\n",
            "Epoch 38/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9165 - accuracy: 0.6217 - val_loss: 0.9397 - val_accuracy: 0.6836\n",
            "Epoch 39/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9115 - accuracy: 0.6158 - val_loss: 0.9316 - val_accuracy: 0.6797\n",
            "Epoch 40/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9103 - accuracy: 0.6188 - val_loss: 0.9293 - val_accuracy: 0.6680\n",
            "Epoch 41/370\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.9091 - accuracy: 0.6080 - val_loss: 0.9242 - val_accuracy: 0.6602\n",
            "Epoch 42/370\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.9072 - accuracy: 0.6207 - val_loss: 0.9314 - val_accuracy: 0.6797\n",
            "Epoch 43/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9077 - accuracy: 0.6109 - val_loss: 0.9256 - val_accuracy: 0.6562\n",
            "Epoch 44/370\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9042 - accuracy: 0.6188 - val_loss: 0.9303 - val_accuracy: 0.6797\n",
            "Epoch 45/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9021 - accuracy: 0.6227 - val_loss: 0.9285 - val_accuracy: 0.6758\n",
            "Epoch 46/370\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.8993 - accuracy: 0.6295 - val_loss: 0.9198 - val_accuracy: 0.6562\n",
            "Epoch 47/370\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.9006 - accuracy: 0.6217 - val_loss: 0.9190 - val_accuracy: 0.6602\n",
            "Epoch 48/370\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.9061 - accuracy: 0.6168 - val_loss: 0.9217 - val_accuracy: 0.6602\n",
            "Epoch 49/370\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.8972 - accuracy: 0.6217 - val_loss: 0.9208 - val_accuracy: 0.6562\n",
            "Epoch 50/370\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.8968 - accuracy: 0.6149 - val_loss: 0.9208 - val_accuracy: 0.6602\n",
            "Epoch 51/370\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.8921 - accuracy: 0.6149 - val_loss: 0.9455 - val_accuracy: 0.6523\n",
            "Epoch 52/370\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.8950 - accuracy: 0.6168 - val_loss: 0.9254 - val_accuracy: 0.6680\n",
            "Epoch 53/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8907 - accuracy: 0.6266 - val_loss: 0.9241 - val_accuracy: 0.6680\n",
            "Epoch 54/370\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.8890 - accuracy: 0.6295 - val_loss: 0.9218 - val_accuracy: 0.6641\n",
            "Epoch 55/370\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.8880 - accuracy: 0.6276 - val_loss: 0.9221 - val_accuracy: 0.6680\n",
            "Epoch 56/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8855 - accuracy: 0.6315 - val_loss: 0.9409 - val_accuracy: 0.6719\n",
            "Epoch 57/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8858 - accuracy: 0.6178 - val_loss: 0.9319 - val_accuracy: 0.6602\n",
            "Epoch 57: early stopping\n",
            "Epoch 1/370\n",
            "29/29 [==============================] - 2s 27ms/step - loss: 1.7420 - accuracy: 0.3255 - val_loss: 1.6452 - val_accuracy: 0.4180\n",
            "Epoch 2/370\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 1.5517 - accuracy: 0.4641"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 10ms/step - loss: 1.5403 - accuracy: 0.4692 - val_loss: 1.3948 - val_accuracy: 0.6016\n",
            "Epoch 3/370\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.2971 - accuracy: 0.5464 - val_loss: 1.1985 - val_accuracy: 0.5469\n",
            "Epoch 4/370\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.1672 - accuracy: 0.5660 - val_loss: 1.1233 - val_accuracy: 0.5508\n",
            "Epoch 5/370\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 1.1152 - accuracy: 0.5709 - val_loss: 1.0807 - val_accuracy: 0.5547\n",
            "Epoch 6/370\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.0777 - accuracy: 0.5689 - val_loss: 1.0445 - val_accuracy: 0.5820\n",
            "Epoch 7/370\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 1.0555 - accuracy: 0.5699 - val_loss: 1.0201 - val_accuracy: 0.5742\n",
            "Epoch 8/370\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.0361 - accuracy: 0.5640 - val_loss: 0.9997 - val_accuracy: 0.5820\n",
            "Epoch 9/370\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0227 - accuracy: 0.5806 - val_loss: 0.9890 - val_accuracy: 0.5703\n",
            "Epoch 10/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 1.0175 - accuracy: 0.5797 - val_loss: 0.9858 - val_accuracy: 0.5547\n",
            "Epoch 11/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 1.0107 - accuracy: 0.5836 - val_loss: 0.9704 - val_accuracy: 0.5820\n",
            "Epoch 12/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 1.0123 - accuracy: 0.5738 - val_loss: 0.9782 - val_accuracy: 0.5742\n",
            "Epoch 13/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9970 - accuracy: 0.5738 - val_loss: 0.9631 - val_accuracy: 0.6211\n",
            "Epoch 14/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9991 - accuracy: 0.5904 - val_loss: 0.9562 - val_accuracy: 0.6094\n",
            "Epoch 15/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9934 - accuracy: 0.5943 - val_loss: 0.9532 - val_accuracy: 0.6055\n",
            "Epoch 16/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9877 - accuracy: 0.5875 - val_loss: 0.9469 - val_accuracy: 0.6172\n",
            "Epoch 17/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9851 - accuracy: 0.5885 - val_loss: 0.9483 - val_accuracy: 0.6055\n",
            "Epoch 18/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9820 - accuracy: 0.5963 - val_loss: 0.9414 - val_accuracy: 0.6250\n",
            "Epoch 19/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9812 - accuracy: 0.5894 - val_loss: 0.9464 - val_accuracy: 0.6055\n",
            "Epoch 20/370\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.9776 - accuracy: 0.5904 - val_loss: 0.9357 - val_accuracy: 0.6250\n",
            "Epoch 21/370\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.9737 - accuracy: 0.5963 - val_loss: 0.9354 - val_accuracy: 0.6211\n",
            "Epoch 22/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9715 - accuracy: 0.6051 - val_loss: 0.9359 - val_accuracy: 0.6172\n",
            "Epoch 23/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9674 - accuracy: 0.5963 - val_loss: 0.9280 - val_accuracy: 0.6328\n",
            "Epoch 24/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9721 - accuracy: 0.6012 - val_loss: 0.9254 - val_accuracy: 0.6172\n",
            "Epoch 25/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9666 - accuracy: 0.6061 - val_loss: 0.9280 - val_accuracy: 0.6289\n",
            "Epoch 26/370\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.9628 - accuracy: 0.6080 - val_loss: 0.9275 - val_accuracy: 0.6211\n",
            "Epoch 27/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9627 - accuracy: 0.6080 - val_loss: 0.9229 - val_accuracy: 0.6289\n",
            "Epoch 28/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9586 - accuracy: 0.6090 - val_loss: 0.9228 - val_accuracy: 0.6250\n",
            "Epoch 29/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9616 - accuracy: 0.6012 - val_loss: 0.9205 - val_accuracy: 0.6289\n",
            "Epoch 30/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9534 - accuracy: 0.6090 - val_loss: 0.9282 - val_accuracy: 0.6211\n",
            "Epoch 31/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9513 - accuracy: 0.6051 - val_loss: 0.9224 - val_accuracy: 0.6250\n",
            "Epoch 32/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9498 - accuracy: 0.6100 - val_loss: 0.9166 - val_accuracy: 0.6406\n",
            "Epoch 33/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9458 - accuracy: 0.6090 - val_loss: 0.9158 - val_accuracy: 0.6211\n",
            "Epoch 34/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9440 - accuracy: 0.6149 - val_loss: 0.9193 - val_accuracy: 0.6133\n",
            "Epoch 35/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9428 - accuracy: 0.6119 - val_loss: 0.9140 - val_accuracy: 0.6367\n",
            "Epoch 36/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9419 - accuracy: 0.6119 - val_loss: 0.9151 - val_accuracy: 0.6250\n",
            "Epoch 37/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9401 - accuracy: 0.6129 - val_loss: 0.9176 - val_accuracy: 0.6367\n",
            "Epoch 38/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9391 - accuracy: 0.6129 - val_loss: 0.9156 - val_accuracy: 0.6523\n",
            "Epoch 39/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9339 - accuracy: 0.6149 - val_loss: 0.9131 - val_accuracy: 0.6289\n",
            "Epoch 40/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9322 - accuracy: 0.6197 - val_loss: 0.9130 - val_accuracy: 0.6367\n",
            "Epoch 41/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9298 - accuracy: 0.6090 - val_loss: 0.9146 - val_accuracy: 0.6328\n",
            "Epoch 42/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9303 - accuracy: 0.6188 - val_loss: 0.9117 - val_accuracy: 0.6445\n",
            "Epoch 43/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9302 - accuracy: 0.6129 - val_loss: 0.9120 - val_accuracy: 0.6328\n",
            "Epoch 44/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9266 - accuracy: 0.6197 - val_loss: 0.9113 - val_accuracy: 0.6445\n",
            "Epoch 45/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9220 - accuracy: 0.6227 - val_loss: 0.9236 - val_accuracy: 0.6172\n",
            "Epoch 46/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9219 - accuracy: 0.6100 - val_loss: 0.9128 - val_accuracy: 0.6289\n",
            "Epoch 47/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9191 - accuracy: 0.6090 - val_loss: 0.9211 - val_accuracy: 0.6289\n",
            "Epoch 48/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9182 - accuracy: 0.6149 - val_loss: 0.9129 - val_accuracy: 0.6367\n",
            "Epoch 49/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9217 - accuracy: 0.6256 - val_loss: 0.9122 - val_accuracy: 0.6328\n",
            "Epoch 50/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9145 - accuracy: 0.6285 - val_loss: 0.9284 - val_accuracy: 0.6211\n",
            "Epoch 51/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9121 - accuracy: 0.6305 - val_loss: 0.9101 - val_accuracy: 0.6484\n",
            "Epoch 52/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9112 - accuracy: 0.6237 - val_loss: 0.9145 - val_accuracy: 0.6445\n",
            "Epoch 53/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9080 - accuracy: 0.6305 - val_loss: 0.9168 - val_accuracy: 0.6367\n",
            "Epoch 54/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9094 - accuracy: 0.6285 - val_loss: 0.9138 - val_accuracy: 0.6484\n",
            "Epoch 55/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9079 - accuracy: 0.6227 - val_loss: 0.9107 - val_accuracy: 0.6484\n",
            "Epoch 56/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9055 - accuracy: 0.6305 - val_loss: 0.9181 - val_accuracy: 0.6367\n",
            "Epoch 57/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9027 - accuracy: 0.6334 - val_loss: 0.9139 - val_accuracy: 0.6406\n",
            "Epoch 58/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9050 - accuracy: 0.6276 - val_loss: 0.9204 - val_accuracy: 0.6328\n",
            "Epoch 59/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9027 - accuracy: 0.6354 - val_loss: 0.9109 - val_accuracy: 0.6562\n",
            "Epoch 60/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9008 - accuracy: 0.6285 - val_loss: 0.9154 - val_accuracy: 0.6328\n",
            "Epoch 61/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9029 - accuracy: 0.6285 - val_loss: 0.9155 - val_accuracy: 0.6406\n",
            "Epoch 61: early stopping\n",
            "Epoch 1/370\n",
            "29/29 [==============================] - 1s 14ms/step - loss: 1.6109 - accuracy: 0.4819 - val_loss: 1.3995 - val_accuracy: 0.5352\n",
            "Epoch 2/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 1.3060 - accuracy: 0.4643 - val_loss: 1.1875 - val_accuracy: 0.5430\n",
            "Epoch 3/370\n",
            " 1/29 [>.............................] - ETA: 0s - loss: 1.1414 - accuracy: 0.5833"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 5ms/step - loss: 1.1711 - accuracy: 0.5709 - val_loss: 1.1113 - val_accuracy: 0.5508\n",
            "Epoch 4/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 1.1053 - accuracy: 0.5601 - val_loss: 1.0678 - val_accuracy: 0.5703\n",
            "Epoch 5/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 1.0635 - accuracy: 0.5709 - val_loss: 1.0393 - val_accuracy: 0.5703\n",
            "Epoch 6/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 1.0325 - accuracy: 0.5758 - val_loss: 1.0371 - val_accuracy: 0.5938\n",
            "Epoch 7/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0130 - accuracy: 0.5797 - val_loss: 1.0122 - val_accuracy: 0.5781\n",
            "Epoch 8/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0016 - accuracy: 0.5904 - val_loss: 1.0104 - val_accuracy: 0.5625\n",
            "Epoch 9/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9889 - accuracy: 0.5806 - val_loss: 1.0079 - val_accuracy: 0.5977\n",
            "Epoch 10/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9818 - accuracy: 0.5846 - val_loss: 0.9990 - val_accuracy: 0.5859\n",
            "Epoch 11/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9742 - accuracy: 0.6012 - val_loss: 0.9995 - val_accuracy: 0.5859\n",
            "Epoch 12/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9684 - accuracy: 0.5934 - val_loss: 0.9975 - val_accuracy: 0.5781\n",
            "Epoch 13/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9679 - accuracy: 0.6031 - val_loss: 0.9977 - val_accuracy: 0.5781\n",
            "Epoch 14/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9647 - accuracy: 0.6031 - val_loss: 0.9954 - val_accuracy: 0.5898\n",
            "Epoch 15/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9587 - accuracy: 0.6100 - val_loss: 0.9985 - val_accuracy: 0.5938\n",
            "Epoch 16/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9593 - accuracy: 0.6061 - val_loss: 1.0019 - val_accuracy: 0.6016\n",
            "Epoch 17/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9488 - accuracy: 0.6119 - val_loss: 0.9947 - val_accuracy: 0.5742\n",
            "Epoch 18/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9499 - accuracy: 0.6100 - val_loss: 0.9979 - val_accuracy: 0.5859\n",
            "Epoch 19/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9505 - accuracy: 0.6188 - val_loss: 1.0189 - val_accuracy: 0.5781\n",
            "Epoch 20/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9568 - accuracy: 0.6080 - val_loss: 1.0035 - val_accuracy: 0.5898\n",
            "Epoch 21/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9494 - accuracy: 0.6158 - val_loss: 0.9906 - val_accuracy: 0.5898\n",
            "Epoch 22/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9412 - accuracy: 0.6100 - val_loss: 0.9885 - val_accuracy: 0.5742\n",
            "Epoch 23/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9385 - accuracy: 0.6149 - val_loss: 0.9923 - val_accuracy: 0.6133\n",
            "Epoch 24/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9457 - accuracy: 0.6178 - val_loss: 0.9852 - val_accuracy: 0.5742\n",
            "Epoch 25/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9340 - accuracy: 0.6139 - val_loss: 0.9926 - val_accuracy: 0.6055\n",
            "Epoch 26/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9407 - accuracy: 0.6090 - val_loss: 0.9864 - val_accuracy: 0.6055\n",
            "Epoch 27/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9377 - accuracy: 0.6109 - val_loss: 0.9813 - val_accuracy: 0.5742\n",
            "Epoch 28/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9296 - accuracy: 0.6266 - val_loss: 0.9859 - val_accuracy: 0.6133\n",
            "Epoch 29/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9297 - accuracy: 0.6217 - val_loss: 0.9816 - val_accuracy: 0.5820\n",
            "Epoch 30/370\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9345 - accuracy: 0.6090 - val_loss: 0.9804 - val_accuracy: 0.5938\n",
            "Epoch 31/370\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9273 - accuracy: 0.6197 - val_loss: 0.9825 - val_accuracy: 0.5859\n",
            "Epoch 32/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9281 - accuracy: 0.6158 - val_loss: 0.9795 - val_accuracy: 0.6016\n",
            "Epoch 33/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9223 - accuracy: 0.6178 - val_loss: 0.9764 - val_accuracy: 0.5938\n",
            "Epoch 34/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9215 - accuracy: 0.6178 - val_loss: 0.9773 - val_accuracy: 0.5977\n",
            "Epoch 35/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9196 - accuracy: 0.6158 - val_loss: 0.9785 - val_accuracy: 0.5938\n",
            "Epoch 36/370\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9196 - accuracy: 0.6129 - val_loss: 0.9735 - val_accuracy: 0.5938\n",
            "Epoch 37/370\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.9168 - accuracy: 0.6227 - val_loss: 0.9746 - val_accuracy: 0.6016\n",
            "Epoch 38/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9196 - accuracy: 0.6178 - val_loss: 0.9760 - val_accuracy: 0.6016\n",
            "Epoch 39/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9172 - accuracy: 0.6188 - val_loss: 0.9736 - val_accuracy: 0.5977\n",
            "Epoch 40/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9105 - accuracy: 0.6217 - val_loss: 0.9709 - val_accuracy: 0.6094\n",
            "Epoch 41/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9102 - accuracy: 0.6256 - val_loss: 0.9781 - val_accuracy: 0.6055\n",
            "Epoch 42/370\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9090 - accuracy: 0.6237 - val_loss: 0.9717 - val_accuracy: 0.5977\n",
            "Epoch 43/370\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.9099 - accuracy: 0.6207 - val_loss: 0.9706 - val_accuracy: 0.6094\n",
            "Epoch 44/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9090 - accuracy: 0.6276 - val_loss: 0.9707 - val_accuracy: 0.6055\n",
            "Epoch 45/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9028 - accuracy: 0.6344 - val_loss: 0.9782 - val_accuracy: 0.6055\n",
            "Epoch 46/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9142 - accuracy: 0.6149 - val_loss: 0.9719 - val_accuracy: 0.6016\n",
            "Epoch 47/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9036 - accuracy: 0.6237 - val_loss: 0.9679 - val_accuracy: 0.6094\n",
            "Epoch 48/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9043 - accuracy: 0.6266 - val_loss: 0.9646 - val_accuracy: 0.6094\n",
            "Epoch 49/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9000 - accuracy: 0.6295 - val_loss: 0.9738 - val_accuracy: 0.6094\n",
            "Epoch 50/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9023 - accuracy: 0.6256 - val_loss: 0.9705 - val_accuracy: 0.5977\n",
            "Epoch 51/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8981 - accuracy: 0.6188 - val_loss: 0.9642 - val_accuracy: 0.6055\n",
            "Epoch 52/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8951 - accuracy: 0.6334 - val_loss: 0.9664 - val_accuracy: 0.6094\n",
            "Epoch 53/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9000 - accuracy: 0.6373 - val_loss: 0.9614 - val_accuracy: 0.6094\n",
            "Epoch 54/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8948 - accuracy: 0.6256 - val_loss: 0.9625 - val_accuracy: 0.6133\n",
            "Epoch 55/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8931 - accuracy: 0.6403 - val_loss: 0.9689 - val_accuracy: 0.6055\n",
            "Epoch 56/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8926 - accuracy: 0.6364 - val_loss: 0.9606 - val_accuracy: 0.6094\n",
            "Epoch 57/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8953 - accuracy: 0.6383 - val_loss: 0.9600 - val_accuracy: 0.6094\n",
            "Epoch 58/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8935 - accuracy: 0.6334 - val_loss: 0.9613 - val_accuracy: 0.6133\n",
            "Epoch 59/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8912 - accuracy: 0.6305 - val_loss: 0.9609 - val_accuracy: 0.6133\n",
            "Epoch 60/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8947 - accuracy: 0.6295 - val_loss: 0.9611 - val_accuracy: 0.6211\n",
            "Epoch 61/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8857 - accuracy: 0.6364 - val_loss: 0.9603 - val_accuracy: 0.5977\n",
            "Epoch 62/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8842 - accuracy: 0.6403 - val_loss: 0.9573 - val_accuracy: 0.6055\n",
            "Epoch 63/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8833 - accuracy: 0.6373 - val_loss: 0.9588 - val_accuracy: 0.6211\n",
            "Epoch 64/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8852 - accuracy: 0.6452 - val_loss: 0.9562 - val_accuracy: 0.6055\n",
            "Epoch 65/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8853 - accuracy: 0.6403 - val_loss: 0.9606 - val_accuracy: 0.6172\n",
            "Epoch 66/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8862 - accuracy: 0.6432 - val_loss: 0.9578 - val_accuracy: 0.6172\n",
            "Epoch 67/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8947 - accuracy: 0.6256 - val_loss: 0.9485 - val_accuracy: 0.6055\n",
            "Epoch 68/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8774 - accuracy: 0.6354 - val_loss: 0.9566 - val_accuracy: 0.5977\n",
            "Epoch 69/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8850 - accuracy: 0.6413 - val_loss: 0.9538 - val_accuracy: 0.6250\n",
            "Epoch 70/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8790 - accuracy: 0.6452 - val_loss: 0.9538 - val_accuracy: 0.5977\n",
            "Epoch 71/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8774 - accuracy: 0.6471 - val_loss: 0.9550 - val_accuracy: 0.6250\n",
            "Epoch 72/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8772 - accuracy: 0.6442 - val_loss: 0.9506 - val_accuracy: 0.6172\n",
            "Epoch 73/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8742 - accuracy: 0.6471 - val_loss: 0.9551 - val_accuracy: 0.6172\n",
            "Epoch 74/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8759 - accuracy: 0.6413 - val_loss: 0.9508 - val_accuracy: 0.6172\n",
            "Epoch 75/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8731 - accuracy: 0.6442 - val_loss: 0.9520 - val_accuracy: 0.6094\n",
            "Epoch 76/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8744 - accuracy: 0.6442 - val_loss: 0.9529 - val_accuracy: 0.6289\n",
            "Epoch 77/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8747 - accuracy: 0.6452 - val_loss: 0.9496 - val_accuracy: 0.6211\n",
            "Epoch 77: early stopping\n",
            "Epoch 1/370\n",
            "29/29 [==============================] - 1s 9ms/step - loss: 1.6924 - accuracy: 0.3900 - val_loss: 1.5551 - val_accuracy: 0.4102\n",
            "Epoch 2/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.4112 - accuracy: 0.4409 - val_loss: 1.2992 - val_accuracy: 0.4414\n",
            "Epoch 3/370\n",
            " 1/29 [>.............................] - ETA: 0s - loss: 1.2236 - accuracy: 0.5000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 4ms/step - loss: 1.1995 - accuracy: 0.5318 - val_loss: 1.1659 - val_accuracy: 0.5352\n",
            "Epoch 4/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.1164 - accuracy: 0.5611 - val_loss: 1.1186 - val_accuracy: 0.5703\n",
            "Epoch 5/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 1.0786 - accuracy: 0.5767 - val_loss: 1.0901 - val_accuracy: 0.5859\n",
            "Epoch 6/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0579 - accuracy: 0.5806 - val_loss: 1.0665 - val_accuracy: 0.5781\n",
            "Epoch 7/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0347 - accuracy: 0.5904 - val_loss: 1.0490 - val_accuracy: 0.5703\n",
            "Epoch 8/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0236 - accuracy: 0.5846 - val_loss: 1.0274 - val_accuracy: 0.5742\n",
            "Epoch 9/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0100 - accuracy: 0.5806 - val_loss: 1.0132 - val_accuracy: 0.5742\n",
            "Epoch 10/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9982 - accuracy: 0.5836 - val_loss: 1.0112 - val_accuracy: 0.5742\n",
            "Epoch 11/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9913 - accuracy: 0.6022 - val_loss: 0.9995 - val_accuracy: 0.5820\n",
            "Epoch 12/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9829 - accuracy: 0.5982 - val_loss: 0.9901 - val_accuracy: 0.6055\n",
            "Epoch 13/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.5973 - val_loss: 0.9812 - val_accuracy: 0.5820\n",
            "Epoch 14/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9749 - accuracy: 0.5924 - val_loss: 0.9777 - val_accuracy: 0.5859\n",
            "Epoch 15/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9737 - accuracy: 0.6100 - val_loss: 0.9862 - val_accuracy: 0.5977\n",
            "Epoch 16/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9649 - accuracy: 0.6100 - val_loss: 0.9724 - val_accuracy: 0.6211\n",
            "Epoch 17/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9660 - accuracy: 0.6012 - val_loss: 0.9722 - val_accuracy: 0.6055\n",
            "Epoch 18/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9695 - accuracy: 0.5904 - val_loss: 0.9717 - val_accuracy: 0.6055\n",
            "Epoch 19/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9609 - accuracy: 0.6041 - val_loss: 0.9692 - val_accuracy: 0.5859\n",
            "Epoch 20/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9568 - accuracy: 0.6168 - val_loss: 0.9658 - val_accuracy: 0.6172\n",
            "Epoch 21/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9572 - accuracy: 0.5992 - val_loss: 0.9645 - val_accuracy: 0.6133\n",
            "Epoch 22/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9505 - accuracy: 0.6100 - val_loss: 0.9631 - val_accuracy: 0.6133\n",
            "Epoch 23/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9493 - accuracy: 0.6031 - val_loss: 0.9642 - val_accuracy: 0.6172\n",
            "Epoch 24/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9483 - accuracy: 0.6080 - val_loss: 0.9617 - val_accuracy: 0.6172\n",
            "Epoch 25/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9452 - accuracy: 0.6158 - val_loss: 0.9652 - val_accuracy: 0.6172\n",
            "Epoch 26/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9416 - accuracy: 0.6197 - val_loss: 0.9622 - val_accuracy: 0.6133\n",
            "Epoch 27/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9442 - accuracy: 0.6080 - val_loss: 0.9606 - val_accuracy: 0.6172\n",
            "Epoch 28/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9356 - accuracy: 0.6217 - val_loss: 0.9608 - val_accuracy: 0.6172\n",
            "Epoch 29/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9364 - accuracy: 0.6168 - val_loss: 0.9589 - val_accuracy: 0.6094\n",
            "Epoch 30/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9353 - accuracy: 0.6188 - val_loss: 0.9559 - val_accuracy: 0.6211\n",
            "Epoch 31/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9353 - accuracy: 0.6149 - val_loss: 0.9599 - val_accuracy: 0.6133\n",
            "Epoch 32/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9312 - accuracy: 0.6051 - val_loss: 0.9732 - val_accuracy: 0.6094\n",
            "Epoch 33/370\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.9310 - accuracy: 0.6178 - val_loss: 0.9820 - val_accuracy: 0.6172\n",
            "Epoch 34/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9266 - accuracy: 0.6197 - val_loss: 0.9528 - val_accuracy: 0.6211\n",
            "Epoch 35/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9355 - accuracy: 0.5943 - val_loss: 0.9560 - val_accuracy: 0.6172\n",
            "Epoch 36/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9265 - accuracy: 0.6295 - val_loss: 0.9517 - val_accuracy: 0.6172\n",
            "Epoch 37/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9235 - accuracy: 0.6266 - val_loss: 0.9677 - val_accuracy: 0.6211\n",
            "Epoch 38/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9223 - accuracy: 0.6237 - val_loss: 0.9526 - val_accuracy: 0.6289\n",
            "Epoch 39/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9210 - accuracy: 0.6149 - val_loss: 0.9519 - val_accuracy: 0.6289\n",
            "Epoch 40/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9173 - accuracy: 0.6315 - val_loss: 0.9500 - val_accuracy: 0.6211\n",
            "Epoch 41/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9200 - accuracy: 0.6178 - val_loss: 0.9483 - val_accuracy: 0.6211\n",
            "Epoch 42/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9234 - accuracy: 0.6207 - val_loss: 0.9542 - val_accuracy: 0.6328\n",
            "Epoch 43/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9125 - accuracy: 0.6354 - val_loss: 0.9472 - val_accuracy: 0.6211\n",
            "Epoch 44/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9107 - accuracy: 0.6305 - val_loss: 0.9547 - val_accuracy: 0.6211\n",
            "Epoch 45/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9100 - accuracy: 0.6295 - val_loss: 0.9472 - val_accuracy: 0.6289\n",
            "Epoch 46/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9085 - accuracy: 0.6246 - val_loss: 0.9566 - val_accuracy: 0.6289\n",
            "Epoch 47/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9089 - accuracy: 0.6207 - val_loss: 0.9423 - val_accuracy: 0.6133\n",
            "Epoch 48/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9072 - accuracy: 0.6325 - val_loss: 0.9489 - val_accuracy: 0.6133\n",
            "Epoch 49/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9046 - accuracy: 0.6354 - val_loss: 0.9572 - val_accuracy: 0.6172\n",
            "Epoch 50/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9042 - accuracy: 0.6276 - val_loss: 0.9488 - val_accuracy: 0.6172\n",
            "Epoch 51/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9064 - accuracy: 0.6246 - val_loss: 0.9485 - val_accuracy: 0.6172\n",
            "Epoch 52/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9032 - accuracy: 0.6188 - val_loss: 0.9443 - val_accuracy: 0.6406\n",
            "Epoch 53/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9039 - accuracy: 0.6227 - val_loss: 0.9435 - val_accuracy: 0.6289\n",
            "Epoch 54/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.9070 - accuracy: 0.6178 - val_loss: 0.9487 - val_accuracy: 0.6211\n",
            "Epoch 55/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.9022 - accuracy: 0.6315 - val_loss: 0.9525 - val_accuracy: 0.6172\n",
            "Epoch 56/370\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.8974 - accuracy: 0.6364 - val_loss: 0.9405 - val_accuracy: 0.6445\n",
            "Epoch 57/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8979 - accuracy: 0.6217 - val_loss: 0.9406 - val_accuracy: 0.6172\n",
            "Epoch 58/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8955 - accuracy: 0.6334 - val_loss: 0.9404 - val_accuracy: 0.6328\n",
            "Epoch 59/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8964 - accuracy: 0.6383 - val_loss: 0.9399 - val_accuracy: 0.6133\n",
            "Epoch 60/370\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.8983 - accuracy: 0.6315 - val_loss: 0.9387 - val_accuracy: 0.6328\n",
            "Epoch 61/370\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.9006 - accuracy: 0.6266 - val_loss: 0.9455 - val_accuracy: 0.6250\n",
            "Epoch 62/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8972 - accuracy: 0.6393 - val_loss: 0.9559 - val_accuracy: 0.6016\n",
            "Epoch 63/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8961 - accuracy: 0.6334 - val_loss: 0.9566 - val_accuracy: 0.6211\n",
            "Epoch 64/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8904 - accuracy: 0.6373 - val_loss: 0.9429 - val_accuracy: 0.6445\n",
            "Epoch 65/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8901 - accuracy: 0.6285 - val_loss: 0.9382 - val_accuracy: 0.6406\n",
            "Epoch 66/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8920 - accuracy: 0.6413 - val_loss: 0.9522 - val_accuracy: 0.6289\n",
            "Epoch 67/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8924 - accuracy: 0.6227 - val_loss: 0.9437 - val_accuracy: 0.6211\n",
            "Epoch 68/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8836 - accuracy: 0.6334 - val_loss: 0.9624 - val_accuracy: 0.6094\n",
            "Epoch 69/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8885 - accuracy: 0.6334 - val_loss: 0.9381 - val_accuracy: 0.6328\n",
            "Epoch 70/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8872 - accuracy: 0.6354 - val_loss: 0.9419 - val_accuracy: 0.6445\n",
            "Epoch 71/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8837 - accuracy: 0.6432 - val_loss: 0.9370 - val_accuracy: 0.6406\n",
            "Epoch 72/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8847 - accuracy: 0.6344 - val_loss: 0.9365 - val_accuracy: 0.6250\n",
            "Epoch 73/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8828 - accuracy: 0.6285 - val_loss: 0.9394 - val_accuracy: 0.6406\n",
            "Epoch 74/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8830 - accuracy: 0.6325 - val_loss: 0.9347 - val_accuracy: 0.6367\n",
            "Epoch 75/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8804 - accuracy: 0.6452 - val_loss: 0.9406 - val_accuracy: 0.6406\n",
            "Epoch 76/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8792 - accuracy: 0.6471 - val_loss: 0.9371 - val_accuracy: 0.6211\n",
            "Epoch 77/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8768 - accuracy: 0.6383 - val_loss: 0.9449 - val_accuracy: 0.6406\n",
            "Epoch 78/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8760 - accuracy: 0.6373 - val_loss: 0.9404 - val_accuracy: 0.6328\n",
            "Epoch 79/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8828 - accuracy: 0.6295 - val_loss: 0.9363 - val_accuracy: 0.6484\n",
            "Epoch 80/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8788 - accuracy: 0.6354 - val_loss: 0.9373 - val_accuracy: 0.6328\n",
            "Epoch 81/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8757 - accuracy: 0.6422 - val_loss: 0.9349 - val_accuracy: 0.6367\n",
            "Epoch 82/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8736 - accuracy: 0.6413 - val_loss: 0.9507 - val_accuracy: 0.6133\n",
            "Epoch 83/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8728 - accuracy: 0.6461 - val_loss: 0.9360 - val_accuracy: 0.6328\n",
            "Epoch 84/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8741 - accuracy: 0.6364 - val_loss: 0.9333 - val_accuracy: 0.6445\n",
            "Epoch 85/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8714 - accuracy: 0.6354 - val_loss: 0.9340 - val_accuracy: 0.6523\n",
            "Epoch 86/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8710 - accuracy: 0.6334 - val_loss: 0.9362 - val_accuracy: 0.6484\n",
            "Epoch 87/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8707 - accuracy: 0.6373 - val_loss: 0.9347 - val_accuracy: 0.6484\n",
            "Epoch 88/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8682 - accuracy: 0.6413 - val_loss: 0.9336 - val_accuracy: 0.6445\n",
            "Epoch 89/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8691 - accuracy: 0.6285 - val_loss: 0.9333 - val_accuracy: 0.6367\n",
            "Epoch 90/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8708 - accuracy: 0.6285 - val_loss: 0.9398 - val_accuracy: 0.6406\n",
            "Epoch 91/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8695 - accuracy: 0.6403 - val_loss: 0.9492 - val_accuracy: 0.6250\n",
            "Epoch 92/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8703 - accuracy: 0.6373 - val_loss: 0.9385 - val_accuracy: 0.6406\n",
            "Epoch 93/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8641 - accuracy: 0.6413 - val_loss: 0.9313 - val_accuracy: 0.6484\n",
            "Epoch 94/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8636 - accuracy: 0.6432 - val_loss: 0.9310 - val_accuracy: 0.6523\n",
            "Epoch 95/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8628 - accuracy: 0.6442 - val_loss: 0.9311 - val_accuracy: 0.6367\n",
            "Epoch 96/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8722 - accuracy: 0.6393 - val_loss: 0.9388 - val_accuracy: 0.6367\n",
            "Epoch 97/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8642 - accuracy: 0.6461 - val_loss: 0.9379 - val_accuracy: 0.6328\n",
            "Epoch 98/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8627 - accuracy: 0.6452 - val_loss: 0.9341 - val_accuracy: 0.6523\n",
            "Epoch 99/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8617 - accuracy: 0.6452 - val_loss: 0.9328 - val_accuracy: 0.6445\n",
            "Epoch 100/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8768 - accuracy: 0.6276 - val_loss: 0.9262 - val_accuracy: 0.6484\n",
            "Epoch 101/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8633 - accuracy: 0.6413 - val_loss: 0.9285 - val_accuracy: 0.6328\n",
            "Epoch 102/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8571 - accuracy: 0.6452 - val_loss: 0.9310 - val_accuracy: 0.6523\n",
            "Epoch 103/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8569 - accuracy: 0.6413 - val_loss: 0.9290 - val_accuracy: 0.6484\n",
            "Epoch 104/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8577 - accuracy: 0.6452 - val_loss: 0.9413 - val_accuracy: 0.6445\n",
            "Epoch 105/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8575 - accuracy: 0.6403 - val_loss: 0.9320 - val_accuracy: 0.6562\n",
            "Epoch 106/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8563 - accuracy: 0.6403 - val_loss: 0.9305 - val_accuracy: 0.6523\n",
            "Epoch 107/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8539 - accuracy: 0.6540 - val_loss: 0.9317 - val_accuracy: 0.6523\n",
            "Epoch 108/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8557 - accuracy: 0.6471 - val_loss: 0.9326 - val_accuracy: 0.6445\n",
            "Epoch 109/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8537 - accuracy: 0.6442 - val_loss: 0.9287 - val_accuracy: 0.6367\n",
            "Epoch 110/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8518 - accuracy: 0.6500 - val_loss: 0.9310 - val_accuracy: 0.6484\n",
            "Epoch 110: early stopping\n",
            "Epoch 1/370\n",
            "29/29 [==============================] - 1s 10ms/step - loss: 1.6717 - accuracy: 0.3232 - val_loss: 1.5128 - val_accuracy: 0.4275\n",
            "Epoch 2/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.3608 - accuracy: 0.3926 - val_loss: 1.2592 - val_accuracy: 0.4784\n",
            "Epoch 3/370\n",
            " 1/29 [>.............................] - ETA: 0s - loss: 1.2627 - accuracy: 0.5278"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 4ms/step - loss: 1.1712 - accuracy: 0.5391 - val_loss: 1.1621 - val_accuracy: 0.5569\n",
            "Epoch 4/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 1.0970 - accuracy: 0.5801 - val_loss: 1.1401 - val_accuracy: 0.4745\n",
            "Epoch 5/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0652 - accuracy: 0.5713 - val_loss: 1.0919 - val_accuracy: 0.5490\n",
            "Epoch 6/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0342 - accuracy: 0.5781 - val_loss: 1.0689 - val_accuracy: 0.5373\n",
            "Epoch 7/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 1.0112 - accuracy: 0.5898 - val_loss: 1.0618 - val_accuracy: 0.5176\n",
            "Epoch 8/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9954 - accuracy: 0.5908 - val_loss: 1.0445 - val_accuracy: 0.5451\n",
            "Epoch 9/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9863 - accuracy: 0.5879 - val_loss: 1.0518 - val_accuracy: 0.5059\n",
            "Epoch 10/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9736 - accuracy: 0.6025 - val_loss: 1.0303 - val_accuracy: 0.5490\n",
            "Epoch 11/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9726 - accuracy: 0.6133 - val_loss: 1.0299 - val_accuracy: 0.5529\n",
            "Epoch 12/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9639 - accuracy: 0.6172 - val_loss: 1.0220 - val_accuracy: 0.5608\n",
            "Epoch 13/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9603 - accuracy: 0.6182 - val_loss: 1.0208 - val_accuracy: 0.5451\n",
            "Epoch 14/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9595 - accuracy: 0.6182 - val_loss: 1.0223 - val_accuracy: 0.5412\n",
            "Epoch 15/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9504 - accuracy: 0.6172 - val_loss: 1.0144 - val_accuracy: 0.5647\n",
            "Epoch 16/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9529 - accuracy: 0.6348 - val_loss: 1.0185 - val_accuracy: 0.5373\n",
            "Epoch 17/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9417 - accuracy: 0.6260 - val_loss: 1.0417 - val_accuracy: 0.5216\n",
            "Epoch 18/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9503 - accuracy: 0.6172 - val_loss: 1.0228 - val_accuracy: 0.5255\n",
            "Epoch 19/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9414 - accuracy: 0.6309 - val_loss: 1.0151 - val_accuracy: 0.5569\n",
            "Epoch 20/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9420 - accuracy: 0.6152 - val_loss: 1.0148 - val_accuracy: 0.5451\n",
            "Epoch 21/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9318 - accuracy: 0.6289 - val_loss: 1.0160 - val_accuracy: 0.5294\n",
            "Epoch 22/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9282 - accuracy: 0.6309 - val_loss: 1.0028 - val_accuracy: 0.5490\n",
            "Epoch 23/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9285 - accuracy: 0.6348 - val_loss: 1.0011 - val_accuracy: 0.5569\n",
            "Epoch 24/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9261 - accuracy: 0.6270 - val_loss: 1.0214 - val_accuracy: 0.5255\n",
            "Epoch 25/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9265 - accuracy: 0.6260 - val_loss: 1.0141 - val_accuracy: 0.5255\n",
            "Epoch 26/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9207 - accuracy: 0.6260 - val_loss: 1.0097 - val_accuracy: 0.5294\n",
            "Epoch 27/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9215 - accuracy: 0.6348 - val_loss: 1.0083 - val_accuracy: 0.5294\n",
            "Epoch 28/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9162 - accuracy: 0.6348 - val_loss: 1.0028 - val_accuracy: 0.5412\n",
            "Epoch 29/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9156 - accuracy: 0.6250 - val_loss: 1.0055 - val_accuracy: 0.5255\n",
            "Epoch 30/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9107 - accuracy: 0.6406 - val_loss: 0.9950 - val_accuracy: 0.5412\n",
            "Epoch 31/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9135 - accuracy: 0.6201 - val_loss: 1.0008 - val_accuracy: 0.5373\n",
            "Epoch 32/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9113 - accuracy: 0.6318 - val_loss: 0.9931 - val_accuracy: 0.5451\n",
            "Epoch 33/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9064 - accuracy: 0.6396 - val_loss: 0.9931 - val_accuracy: 0.5490\n",
            "Epoch 34/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9059 - accuracy: 0.6348 - val_loss: 0.9917 - val_accuracy: 0.5412\n",
            "Epoch 35/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9082 - accuracy: 0.6318 - val_loss: 0.9967 - val_accuracy: 0.5333\n",
            "Epoch 36/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.9095 - accuracy: 0.6328 - val_loss: 0.9985 - val_accuracy: 0.5373\n",
            "Epoch 37/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9009 - accuracy: 0.6475 - val_loss: 0.9936 - val_accuracy: 0.5373\n",
            "Epoch 38/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8980 - accuracy: 0.6426 - val_loss: 0.9923 - val_accuracy: 0.5216\n",
            "Epoch 39/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8993 - accuracy: 0.6455 - val_loss: 0.9921 - val_accuracy: 0.5451\n",
            "Epoch 40/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8957 - accuracy: 0.6465 - val_loss: 0.9941 - val_accuracy: 0.5255\n",
            "Epoch 41/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.9028 - accuracy: 0.6338 - val_loss: 0.9870 - val_accuracy: 0.5490\n",
            "Epoch 42/370\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.8938 - accuracy: 0.6387 - val_loss: 1.0177 - val_accuracy: 0.5098\n",
            "Epoch 43/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8950 - accuracy: 0.6484 - val_loss: 0.9901 - val_accuracy: 0.5373\n",
            "Epoch 44/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8934 - accuracy: 0.6455 - val_loss: 0.9934 - val_accuracy: 0.5373\n",
            "Epoch 45/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8900 - accuracy: 0.6475 - val_loss: 0.9866 - val_accuracy: 0.5529\n",
            "Epoch 46/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8924 - accuracy: 0.6396 - val_loss: 0.9880 - val_accuracy: 0.5294\n",
            "Epoch 47/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8855 - accuracy: 0.6494 - val_loss: 0.9993 - val_accuracy: 0.5294\n",
            "Epoch 48/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8878 - accuracy: 0.6436 - val_loss: 1.0035 - val_accuracy: 0.5373\n",
            "Epoch 49/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8880 - accuracy: 0.6484 - val_loss: 0.9962 - val_accuracy: 0.5255\n",
            "Epoch 50/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8831 - accuracy: 0.6494 - val_loss: 0.9897 - val_accuracy: 0.5294\n",
            "Epoch 51/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8837 - accuracy: 0.6465 - val_loss: 0.9829 - val_accuracy: 0.5373\n",
            "Epoch 52/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8804 - accuracy: 0.6406 - val_loss: 1.0006 - val_accuracy: 0.5373\n",
            "Epoch 53/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8824 - accuracy: 0.6523 - val_loss: 0.9880 - val_accuracy: 0.5490\n",
            "Epoch 54/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8834 - accuracy: 0.6416 - val_loss: 0.9904 - val_accuracy: 0.5137\n",
            "Epoch 55/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8823 - accuracy: 0.6484 - val_loss: 0.9943 - val_accuracy: 0.5216\n",
            "Epoch 56/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8818 - accuracy: 0.6396 - val_loss: 0.9929 - val_accuracy: 0.5255\n",
            "Epoch 57/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8750 - accuracy: 0.6445 - val_loss: 0.9848 - val_accuracy: 0.5451\n",
            "Epoch 58/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8768 - accuracy: 0.6426 - val_loss: 0.9993 - val_accuracy: 0.5412\n",
            "Epoch 59/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8737 - accuracy: 0.6484 - val_loss: 0.9823 - val_accuracy: 0.5412\n",
            "Epoch 60/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8707 - accuracy: 0.6455 - val_loss: 1.0139 - val_accuracy: 0.5216\n",
            "Epoch 61/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8759 - accuracy: 0.6533 - val_loss: 0.9837 - val_accuracy: 0.5294\n",
            "Epoch 62/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8788 - accuracy: 0.6543 - val_loss: 0.9803 - val_accuracy: 0.5608\n",
            "Epoch 63/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8723 - accuracy: 0.6514 - val_loss: 1.0071 - val_accuracy: 0.5333\n",
            "Epoch 64/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8721 - accuracy: 0.6504 - val_loss: 0.9834 - val_accuracy: 0.5490\n",
            "Epoch 65/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8673 - accuracy: 0.6455 - val_loss: 0.9866 - val_accuracy: 0.5255\n",
            "Epoch 66/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8705 - accuracy: 0.6514 - val_loss: 1.0035 - val_accuracy: 0.5333\n",
            "Epoch 67/370\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.8791 - accuracy: 0.6475 - val_loss: 1.0034 - val_accuracy: 0.5412\n",
            "Epoch 68/370\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.8696 - accuracy: 0.6592 - val_loss: 1.0027 - val_accuracy: 0.5412\n",
            "Epoch 69/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8647 - accuracy: 0.6514 - val_loss: 0.9904 - val_accuracy: 0.5294\n",
            "Epoch 70/370\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.8638 - accuracy: 0.6533 - val_loss: 0.9941 - val_accuracy: 0.5373\n",
            "Epoch 71/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8716 - accuracy: 0.6475 - val_loss: 0.9959 - val_accuracy: 0.5294\n",
            "Epoch 72/370\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.8654 - accuracy: 0.6514 - val_loss: 0.9817 - val_accuracy: 0.5529\n",
            "Epoch 72: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 교차 검증 결과 분석\n",
        "average_accuracy = np.mean(acc_per_fold)\n",
        "print(f'Average accuracy across all folds: {average_accuracy:.2f}%')\n",
        "\n",
        "# 정확도 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, k+1), acc_per_fold, marker='o', linestyle='-', color='b')\n",
        "plt.title('Accuracy per Fold')\n",
        "plt.xlabel('Fold Number')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.xticks(range(1, k+1))\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "HVN_e-cZKvEm",
        "outputId": "46b7e89a-fc43-4711-cedb-e800c117e00d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy across all folds: 62.47%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 데이터셋에 대한 모델 성능 평가\n",
        "# 전체 데이터셋에 대해 동일한 모델 아키텍처를 사용하여 학습 및 평가를 수행합\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_shape=(X_scaled.shape[1],), activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model.fit(X_scaled, y, epochs=100, batch_size=32, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKCwQ4mqK2Ud",
        "outputId": "f3ea1e21-1416-4848-d0be-b078fad898fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 1s 4ms/step - loss: 1.6591 - accuracy: 0.3465\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.2768 - accuracy: 0.4390\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.1077 - accuracy: 0.5578\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.0446 - accuracy: 0.5710\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.0119 - accuracy: 0.5716\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.9954 - accuracy: 0.5791\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.9832 - accuracy: 0.5860\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.9774 - accuracy: 0.5866\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.9700 - accuracy: 0.5841\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.9685 - accuracy: 0.5904\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.9599 - accuracy: 0.5941\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.9571 - accuracy: 0.6073\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 1s 10ms/step - loss: 0.9518 - accuracy: 0.6054\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.9586 - accuracy: 0.5904\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.9455 - accuracy: 0.6004\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 1s 11ms/step - loss: 0.9433 - accuracy: 0.6054\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 1s 15ms/step - loss: 0.9420 - accuracy: 0.6091\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 1s 13ms/step - loss: 0.9400 - accuracy: 0.5979\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.9355 - accuracy: 0.6104\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.9364 - accuracy: 0.6010\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.9372 - accuracy: 0.6085\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.9268 - accuracy: 0.6073\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.9264 - accuracy: 0.6129\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.9303 - accuracy: 0.5997\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.9206 - accuracy: 0.6191\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9222 - accuracy: 0.6141\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.9232 - accuracy: 0.6079\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.9181 - accuracy: 0.6173\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.9151 - accuracy: 0.6154\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.9161 - accuracy: 0.6135\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.9135 - accuracy: 0.6185\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.9111 - accuracy: 0.6160\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.9073 - accuracy: 0.6248\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.9045 - accuracy: 0.6229\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.9048 - accuracy: 0.6248\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.9027 - accuracy: 0.6173\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.8993 - accuracy: 0.6235\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.9017 - accuracy: 0.6266\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8991 - accuracy: 0.6235\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.9021 - accuracy: 0.6273\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8992 - accuracy: 0.6229\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8925 - accuracy: 0.6273\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8892 - accuracy: 0.6266\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8975 - accuracy: 0.6191\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8909 - accuracy: 0.6291\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8921 - accuracy: 0.6260\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8830 - accuracy: 0.6323\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8940 - accuracy: 0.6273\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8845 - accuracy: 0.6329\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8838 - accuracy: 0.6298\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8847 - accuracy: 0.6329\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8883 - accuracy: 0.6260\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8928 - accuracy: 0.6235\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8813 - accuracy: 0.6273\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8790 - accuracy: 0.6304\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8822 - accuracy: 0.6304\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8761 - accuracy: 0.6360\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8792 - accuracy: 0.6341\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8767 - accuracy: 0.6335\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8766 - accuracy: 0.6373\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8793 - accuracy: 0.6304\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8741 - accuracy: 0.6379\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8803 - accuracy: 0.6354\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8751 - accuracy: 0.6398\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8720 - accuracy: 0.6385\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8741 - accuracy: 0.6398\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8682 - accuracy: 0.6391\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8669 - accuracy: 0.6360\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8694 - accuracy: 0.6429\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8706 - accuracy: 0.6291\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8673 - accuracy: 0.6379\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8690 - accuracy: 0.6366\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8654 - accuracy: 0.6360\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8636 - accuracy: 0.6354\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8652 - accuracy: 0.6467\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8631 - accuracy: 0.6460\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8644 - accuracy: 0.6435\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8611 - accuracy: 0.6398\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8609 - accuracy: 0.6366\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8582 - accuracy: 0.6379\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8670 - accuracy: 0.6329\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8600 - accuracy: 0.6454\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8582 - accuracy: 0.6442\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8586 - accuracy: 0.6442\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8576 - accuracy: 0.6391\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8580 - accuracy: 0.6460\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8606 - accuracy: 0.6417\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8599 - accuracy: 0.6467\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8563 - accuracy: 0.6448\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8572 - accuracy: 0.6448\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8546 - accuracy: 0.6423\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8529 - accuracy: 0.6479\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8528 - accuracy: 0.6435\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8528 - accuracy: 0.6492\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8513 - accuracy: 0.6523\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8503 - accuracy: 0.6504\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8498 - accuracy: 0.6429\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8463 - accuracy: 0.6467\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8502 - accuracy: 0.6435\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8490 - accuracy: 0.6423\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d780d0753c0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 테스트 세트에서 성능 평가\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test Set Accuracy: {test_accuracy*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OmhpV6HLCSt",
        "outputId": "01be3880-bde7-4a7c-84a1-0ae83f500d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Accuracy: 63.75%\n"
          ]
        }
      ]
    }
  ]
}